{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9207f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import openai\n",
    "import pymssql\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from threading import Thread\n",
    "import functools\n",
    "from tableone import TableOne\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import mannwhitneyu as mwu\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "from lifelines.statistics import multivariate_logrank_test\n",
    "from sksurv.nonparametric import kaplan_meier_estimator\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import random\n",
    "\n",
    "table_name=\"\" #enter table name\n",
    "df=pd.read_csv(table_name+'/'+table_name+'.csv')\n",
    "seednum=3\n",
    "random.seed(seednum)\n",
    "rrr=list(range(len(df)))\n",
    "random.shuffle(rrr)\n",
    "\n",
    "conn = pymssql.connect()# enter connection info\n",
    "\n",
    "openai.api_key = \"\" #enter api key\n",
    "\n",
    "df=df.iloc[rrr]\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "\n",
    "input_text_temp=df['input_text5']\n",
    "\n",
    "\n",
    "iterations=5\n",
    "upto=50000\n",
    "\n",
    "\n",
    "usercontent_global1='''Estimate the risk (in percentages) of developing a cardiovascular disease within 10 years for the person below.\n",
    "\n",
    "'''\n",
    "\n",
    "usercontent_global2='''\n",
    "\n",
    "Please answer exactly in the format below, without blank lines, and no further information or answer is required.\n",
    "Risk percentage=(in percentages, round to one decimal place)'''\n",
    "\n",
    "\n",
    "############################\n",
    "\n",
    "\n",
    "eid=df['eid']\n",
    "Framingham=df['Framingham']\n",
    "ACC_AHA=df['ACC/AHA']\n",
    "\n",
    "from threading import Thread\n",
    "import functools\n",
    "\n",
    "def timeout(timeout):\n",
    "    def deco(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            res = [Exception('function [%s] timeout [%s seconds] exceeded!' % (func.__name__, timeout))]\n",
    "            def newFunc():\n",
    "                try:\n",
    "                    res[0] = func(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    res[0] = e\n",
    "            t = Thread(target=newFunc)\n",
    "            t.daemon = True\n",
    "            try:\n",
    "                t.start()\n",
    "                t.join(timeout)\n",
    "            except Exception as je:\n",
    "                print ('error starting thread')\n",
    "                raise je\n",
    "            ret = res[0]\n",
    "            #if isinstance(ret, BaseException):\n",
    "            #    raise ret\n",
    "            return ret\n",
    "        return wrapper\n",
    "    return deco\n",
    "\n",
    "\n",
    "@timeout(0.37)\n",
    "def ChatGPT_main(i,texttype,temper):\n",
    "    input_text=texttype\n",
    "    if input_text[i]!='':\n",
    "        try:\n",
    "            usercontent=usercontent_global1\n",
    "            usercontent+=input_text[i]\n",
    "            usercontent+=usercontent_global2\n",
    "\n",
    "            messages=[\n",
    "                    {\"role\": \"user\", \"content\": usercontent}\n",
    "                ]\n",
    "\n",
    "            completion=openai.ChatCompletion.create(model=\"gpt-4\", \n",
    "                                                    messages=messages,\n",
    "                                                    temperature=temper)\n",
    "\n",
    "\n",
    "            aa=completion.choices[0].message.content.split('\\n')\n",
    "            #print(aa)\n",
    "            remove_set={''}\n",
    "            aaa=[i for i in aa if i not in remove_set]\n",
    "\n",
    "            temp1='blank'\n",
    "            temp2=aaa[0].split('=')[1]\n",
    "            temp3='blank'\n",
    "            temp4=Framingham[i]\n",
    "            temp5=ACC_AHA[i]\n",
    "\n",
    "        except:\n",
    "            temp1=np.nan\n",
    "            temp2=np.nan\n",
    "            temp3=np.nan\n",
    "            temp4=np.nan\n",
    "            temp5=np.nan\n",
    "            except_else_num+=1\n",
    "    else:\n",
    "        temp1=np.nan\n",
    "        temp2=np.nan\n",
    "        temp3=np.nan\n",
    "        temp4=np.nan\n",
    "        temp5=np.nan\n",
    "        except_else_num+=1\n",
    "\n",
    "    conn = pymssql.connect()# enter connection info\n",
    "\n",
    "    with conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(sql, (str(eid[i]),temp1,temp2,temp3,temp4,temp5))\n",
    "            conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c7684f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############################\n",
    "table_name=\"\" #enter table name\n",
    "############################\n",
    "for temper in [0.4]:\n",
    "    for i in range(5,5+iterations):   \n",
    "        newtablaname=table_name + '_' + str(int(temper*10)) + '_' + str(i)\n",
    "        sql_createtable=\"CREATE TABLE [\" + newtablaname +\"\"\"] \n",
    "        (\n",
    "            eid    NVARCHAR(20),\n",
    "            system    NVARCHAR(max),\n",
    "            score      NVARCHAR(max),\n",
    "            category     NVARCHAR(max) ,\n",
    "            framingham  NVARCHAR(20),\n",
    "            ACC_AHA  NVARCHAR(20)\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        conn = pymssql.connect()# enter connection info\n",
    "        with conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(sql_createtable)\n",
    "                conn.commit()\n",
    "        time.sleep(1)        \n",
    "        sql = \"INSERT INTO [\" + newtablaname+\"] (eid, system,score,category,framingham,ACC_AHA) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "        except_else_num=0\n",
    "        time1=datetime.datetime.now()\n",
    "        for j in range(upto):\n",
    "            while True:\n",
    "                if j%1000==0:\n",
    "                    print(j)\n",
    "                ChatGPT_main(j,input_text_temp,temper)\n",
    "                break\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "\n",
    "        time2=datetime.datetime.now()\n",
    "        print(time2-time1)\n",
    "        print('except_else_num = ',except_else_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0570fa2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check & fill missing rows\n",
    "for temper in [0.4]:\n",
    "    while True:\n",
    "        toggle=0\n",
    "        for i in range(5,5+iterations):   \n",
    "            newtablaname=table_name + '_' + str(int(temper*10)) + '_' + str(i)\n",
    "            \n",
    "            try:\n",
    "                sql_createtable=\"CREATE TABLE [\" + newtablaname +\"\"\"] \n",
    "                (\n",
    "                    eid    NVARCHAR(20),\n",
    "                    system    NVARCHAR(max),\n",
    "                    score      NVARCHAR(max),\n",
    "                    category     NVARCHAR(max) ,\n",
    "                    framingham  NVARCHAR(20),\n",
    "                    ACC_AHA  NVARCHAR(20)\n",
    "                )\n",
    "\n",
    "                \"\"\"\n",
    "                conn = pymssql.connect()# enter connection info\n",
    "                with conn:\n",
    "                    with conn.cursor() as cur:\n",
    "                        cur.execute(sql_createtable)\n",
    "                        conn.commit()\n",
    "                time.sleep(1)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "\n",
    "            sql_statement=\"select * from [\"+ newtablaname + \"]\"\n",
    "            conn = pymssql.connect()# enter connection info\n",
    "            globals()['data{}'.format(i)] = pd.read_sql(sql=sql_statement, con=conn)\n",
    "            globals()['data{}'.format(i)]=globals()['data{}'.format(i)].astype({'eid':int})\n",
    "            globals()['data{}_eid'.format(i)]=list(globals()['data{}'.format(i)]['eid'])\n",
    "            countaaaaa=0\n",
    "            countcount=0\n",
    "            time1=datetime.datetime.now()\n",
    "            for j in range(upto):\n",
    "                if df['eid'][j] not in globals()['data{}_eid'.format(i)]:\n",
    "\n",
    "                    sql = \"INSERT INTO [\" + newtablaname+ \"] (eid, system,score,category,framingham,ACC_AHA) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "                    ChatGPT_main(j,input_text_temp,temper)\n",
    "                    countcount+=1\n",
    "                    if countcount%200==1:\n",
    "                        print(j)\n",
    "                        time2=datetime.datetime.now()\n",
    "                        print(time2-time1)\n",
    "                    countaaaaa+=1\n",
    "\n",
    "            time.sleep(10)\n",
    "            if countaaaaa==0:\n",
    "                toggle=1\n",
    "        if toggle==1:\n",
    "            break\n",
    "    print('====temper',temper,'done=======')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfc8f92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############################\n",
    "table_name=\"\" #enter table name\n",
    "iterations=5\n",
    "upto=50000\n",
    "############################\n",
    "\n",
    "for numnumnumnum in range(1):\n",
    "    for temper in [0.4]:\n",
    "    #for temper in [1]:\n",
    "\n",
    "        txt=''\n",
    "\n",
    "        cutofftxt=''\n",
    "        for i in range(iterations):\n",
    "            newtablename=table_name + '_' + str(int(temper*10)) + '_' + str(i+numnumnumnum)\n",
    "\n",
    "            sql_statement=\"select * from [\"+ newtablename + \"]\"\n",
    "            conn = pymssql.connect()# enter connection info\n",
    "            globals()['data{}'.format(i)] = pd.read_sql(sql=sql_statement, con=conn)\n",
    "            globals()['data{}'.format(i)]['rank_by_eid']=globals()['data{}'.format(i)].groupby('eid')['system'].rank(method='first')\n",
    "            globals()['data{}'.format(i)]=globals()['data{}'.format(i)][globals()['data{}'.format(i)]['rank_by_eid']==1]\n",
    "            globals()['data{}'.format(i)].reset_index(inplace=True,drop=True)\n",
    "            globals()['data{}'.format(i)].drop(['rank_by_eid'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "        for j in range(iterations):\n",
    "            dat=globals()['data{}'.format(j)]\n",
    "\n",
    "            eid=dat['eid']\n",
    "            score_gpt=dat['score']\n",
    "            category=dat['category']\n",
    "            score_framingham=dat['framingham']\n",
    "            score_acc_aha=dat['ACC_AHA']\n",
    "\n",
    "            score_gpt2=[]\n",
    "\n",
    "            for i in range(len(score_gpt)):\n",
    "                try:\n",
    "                    score_gpt2.append(float(re.findall(\"\\d+[.]\\d+[%]\",score_gpt[i])[0].split('%')[0]))\n",
    "                except:\n",
    "                    try:\n",
    "                        score_gpt2.append(float(re.findall(\"\\d+[%]\",score_gpt[i])[0].split('%')[0]))\n",
    "                    except:\n",
    "                        try:\n",
    "                            score_gpt2.append(float(re.findall(\"\\d+[.]\\d+\",score_gpt[i])[0]))\n",
    "                        except:\n",
    "                            try:\n",
    "                                score_gpt2.append(float(re.findall(\"\\d+\",score_gpt[i])[-1]))\n",
    "                            except:\n",
    "                                #score_gpt2.append(np.nan)\n",
    "                                score_gpt2.append(float(score_framingham[i]))\n",
    "                                print(score_gpt[i],'====')\n",
    "\n",
    "\n",
    "            category2=[]\n",
    "            for i in range(len(score_gpt2)):\n",
    "                try:\n",
    "                    if np.isnan(score_gpt2[i])==False:\n",
    "                        if score_gpt2[i]>20:\n",
    "                            category2.append('High')\n",
    "                        elif score_gpt2[i]>10:\n",
    "                            category2.append('Moderate')\n",
    "                        else:\n",
    "                            category2.append('Low')\n",
    "                    else:\n",
    "                        category2.append(np.nan)\n",
    "                except:\n",
    "                    category2.append('Low')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            columnname_score='score'+str(j)\n",
    "            columnname_cat='category'+str(j)\n",
    "            globals()['data{}_1'.format(j)]=pd.DataFrame({'eid':eid,columnname_score:score_gpt2,columnname_cat:category2})\n",
    "            globals()['data{}_1'.format(j)]=globals()['data{}_1'.format(j)].dropna(axis=0)\n",
    "            globals()['data{}_1'.format(j)].reset_index(inplace=True,drop=True)\n",
    "\n",
    "        df2_0=df.iloc[:upto]\n",
    "\n",
    "        for i in range(iterations):\n",
    "            globals()['data{}_1'.format(i)] = globals()['data{}_1'.format(i)].astype({ 'eid' : 'int' })\n",
    "\n",
    "        for i in range(iterations):\n",
    "            globals()['df2_{}'.format(i+1)] = pd.merge(globals()['df2_{}'.format(i)], globals()['data{}_1'.format(i)], left_on='eid', right_on='eid', how='left')\n",
    "\n",
    "        globals()['df2_{}'.format(1)].drop_duplicates(inplace=True,ignore_index=True)\n",
    "        print(\"length\",len(globals()['df2_{}'.format(1)]))\n",
    "\n",
    "        for j in range(iterations):\n",
    "            globals()['category{}_int'.format(j)]=[]\n",
    "\n",
    "        for j in range(iterations):\n",
    "            columnname='category'+str(j)\n",
    "            for i in range(len(globals()['df2_{}'.format(iterations)])):\n",
    "                if globals()['df2_{}'.format(iterations)][columnname][i]=='Low':\n",
    "                    globals()['category{}_int'.format(j)].append(1)\n",
    "                elif globals()['df2_{}'.format(iterations)][columnname][i]=='Moderate':\n",
    "                    globals()['category{}_int'.format(j)].append(2)\n",
    "                else:\n",
    "                    globals()['category{}_int'.format(j)].append(3)\n",
    "\n",
    "        df_final=globals()['df2_{}'.format(iterations)]\n",
    "\n",
    "        for j in range(iterations):\n",
    "            columnname='category'+str(j)+'_int'\n",
    "            df_final[columnname]=globals()['category{}_int'.format(j)]\n",
    "\n",
    "        score_final=[]\n",
    "        category_final=[]\n",
    "        for i in range(len(df_final)):\n",
    "            score_temp=[]\n",
    "            category_temp=[]\n",
    "            for j in range(iterations):\n",
    "                columnname1='score'+str(j)\n",
    "                columname2='category'+str(j)+'_int'\n",
    "                score_temp.append(df_final[columnname1][i])\n",
    "                category_temp.append(df_final[columname2][i])\n",
    "\n",
    "            score_temptemp=np.nanmean(score_temp)\n",
    "            category_temptemp=np.nanmedian(category_temp)\n",
    "            score_final.append(score_temptemp)\n",
    "            category_final.append(category_temptemp)\n",
    "\n",
    "        df_final['score_final']=score_final\n",
    "        df_final['category_final']=category_final\n",
    "\n",
    "\n",
    "        scorefinallist=list(df_final['score_final'])\n",
    "        t1=np.percentile(scorefinallist,100/3)\n",
    "        t2=np.percentile(scorefinallist,200/3)\n",
    "        newcatfinal=[]\n",
    "        for i in range(len(df_final)):\n",
    "            if df_final['score_final'][i]<=t1:\n",
    "                newcatfinal.append(1)\n",
    "            elif df_final['score_final'][i]<=t2:\n",
    "                newcatfinal.append(2)\n",
    "            else:\n",
    "                newcatfinal.append(3)\n",
    "        df_final['category_final']=newcatfinal\n",
    "\n",
    "\n",
    "\n",
    "        cig_final=[]\n",
    "        for i in range(len(df_final)):\n",
    "            if df_final['smoking'][i]==2:\n",
    "                cig_final.append(1)\n",
    "            else:\n",
    "                cig_final.append(0)\n",
    "        df_final['Smoking']=cig_final\n",
    "\n",
    "        df_final['death_date']=pd.to_datetime(df_final['death_date'])\n",
    "        df_final['assess_date']=pd.to_datetime(df_final['assess_date'])\n",
    "        df_final['datediff']=df_final['death_date']-df_final['assess_date']\n",
    "\n",
    "        datediff_int=[]\n",
    "        for i in range(len(df_final)):\n",
    "            datediff_int.append(df_final['datediff'][i].days)\n",
    "\n",
    "        df_final['datediff_int']=datediff_int\n",
    "\n",
    "        datediff_int2=[]\n",
    "        event=[]\n",
    "        for i in range(len(df_final)):\n",
    "            if np.isnan(df_final['datediff_int'][i])==True:\n",
    "                datediff_int2.append(3650)\n",
    "                event.append(False)\n",
    "            else:\n",
    "                if df_final['datediff_int'][i]>3650:\n",
    "                    datediff_int2.append(3650)\n",
    "                    event.append(False)\n",
    "                else:\n",
    "                    datediff_int2.append(df_final['datediff_int'][i])\n",
    "                    event.append(True)\n",
    "        df_final['datediff_int2']=datediff_int2\n",
    "        df_final['event']=event\n",
    "\n",
    "        aa=list(df_final['datediff_int2'])\n",
    "        aa2=[x for x in aa if x < 3650]\n",
    "        aaa=[x for x in aa if x >=0]\n",
    "        aaaa=[x for x in aaa if x < 3650]\n",
    "        exclusion_event_before_assessment=len(aa2)-len(aaaa)\n",
    "        bb=exclusion_event_before_assessment\n",
    "\n",
    "        print('allcausemortality_within10years=',len(aa2)-bb,'/',upto-bb, \", exclusion_event_before_assessment=\",bb)\n",
    "\n",
    "        txt+= (  'allcausemortality_within10years=' + str(len(aa2)-bb) + ' / ' + str(upto-bb)+ \" , exclusion_event_before_assessment= \"+ str(bb) + '\\n'  )\n",
    "\n",
    "        algo=pd.read_csv('ukb_algorithmic_outcome.csv')\n",
    "        algo=algo[['eid','Min_Date']]\n",
    "        algo.columns=['eid','algo_date']\n",
    "        algo['algo_date']=pd.to_datetime(algo['algo_date'])\n",
    "\n",
    "        firstoccur=pd.read_csv('ukb_new_add_first_occur.csv')\n",
    "        firstoccur=firstoccur[['eid','Min_Date']]\n",
    "        firstoccur.columns=['eid','firstoccur_date']\n",
    "        firstoccur['firstoccur_date']=pd.to_datetime(firstoccur['firstoccur_date'])\n",
    "\n",
    "        df_final=pd.merge(df_final, algo, left_on='eid', right_on='eid', how='left')\n",
    "        df_final=pd.merge(df_final, firstoccur, left_on='eid', right_on='eid', how='left')\n",
    "\n",
    "        df_final['datediff_algo']=df_final['algo_date']-df_final['assess_date']\n",
    "        df_final['datediff_firstoccur']=df_final['firstoccur_date']-df_final['assess_date']\n",
    "\n",
    "        datediff_int=[]\n",
    "        for i in range(len(df_final)):\n",
    "            datediff_int.append(df_final['datediff_algo'][i].days)\n",
    "\n",
    "        df_final['datediff_algo_int']=datediff_int\n",
    "\n",
    "        datediff_int2=[]\n",
    "        event=[]\n",
    "        for i in range(len(df_final)):\n",
    "            if np.isnan(df_final['datediff_algo_int'][i])==True:\n",
    "                datediff_int2.append(3650)\n",
    "                event.append(False)\n",
    "            else:\n",
    "                if df_final['datediff_algo_int'][i]>3650:\n",
    "                    datediff_int2.append(3650)\n",
    "                    event.append(False)\n",
    "                else:\n",
    "                    datediff_int2.append(df_final['datediff_algo_int'][i])\n",
    "                    event.append(True)\n",
    "        df_final['datediff_algo_int2']=datediff_int2\n",
    "        df_final['algo_event']=event\n",
    "\n",
    "        aa=list(df_final['datediff_algo_int2'])\n",
    "        aa2=[x for x in aa if x < 3650]\n",
    "        aaa=[x for x in aa if x >=0]\n",
    "        aaaa=[x for x in aaa if x < 3650]\n",
    "        exclusion_event_before_assessment=len(aa2)-len(aaaa)\n",
    "        bb=exclusion_event_before_assessment\n",
    "        print('algoMACE_within10years=',len(aa2)-bb,'/',upto-bb, \", exclusion_event_before_assessment=\",bb)\n",
    "\n",
    "        txt+= (  'algoMACE_within10years=' + str(len(aa2)-bb) + ' / ' + str(upto-bb)+ \" , exclusion_event_before_assessment= \"+ str(bb) + '\\n'  )\n",
    "\n",
    "\n",
    "        datediff_int=[]\n",
    "        for i in range(len(df_final)):\n",
    "            datediff_int.append(df_final['datediff_firstoccur'][i].days)\n",
    "\n",
    "        df_final['datediff_firstoccur_int']=datediff_int\n",
    "\n",
    "        datediff_int2=[]\n",
    "        event=[]\n",
    "        for i in range(len(df_final)):\n",
    "            if np.isnan(df_final['datediff_firstoccur_int'][i])==True:\n",
    "                datediff_int2.append(3650)\n",
    "                event.append(False)\n",
    "            else:\n",
    "                if df_final['datediff_firstoccur_int'][i]>3650:\n",
    "                    datediff_int2.append(3650)\n",
    "                    event.append(False)\n",
    "                else:\n",
    "                    datediff_int2.append(df_final['datediff_firstoccur_int'][i])\n",
    "                    event.append(True)\n",
    "        df_final['datediff_firstoccur_int2']=datediff_int2\n",
    "        df_final['firstoccur_event']=event\n",
    "\n",
    "        aa=list(df_final['datediff_firstoccur_int2'])\n",
    "        aa2=[x for x in aa if x < 3650]\n",
    "        aaa=[x for x in aa if x >=0]\n",
    "        aaaa=[x for x in aaa if x < 3650]\n",
    "        exclusion_event_before_assessment=len(aa2)-len(aaaa)\n",
    "        bb=exclusion_event_before_assessment\n",
    "        print('firstoccurMACE_within10years=',len(aa2)-bb,'/',upto-bb, \", exclusion_event_before_assessment=\",bb)\n",
    "\n",
    "        txt+= (  'firstoccurMACE_within10years=' + str(len(aa2)-bb) + ' / ' + str(upto-bb)+ \" , exclusion_event_before_assessment= \"+ str(bb) + '\\n'  )\n",
    "\n",
    "        \n",
    "        ###################    \n",
    "        df_final=df_final[df_final['datediff_firstoccur_int2']<=3650]\n",
    "        df_final=df_final[df_final['datediff_firstoccur_int2']>=0]\n",
    "        df_final.reset_index(inplace=True,drop=True)\n",
    "\n",
    "\n",
    "        scorefinallist=list(df_final['score_final'])\n",
    "        t1=np.percentile(scorefinallist,100/3)\n",
    "        t2=np.percentile(scorefinallist,200/3)\n",
    "        newcatfinal=[]\n",
    "        t1=10\n",
    "        t2=20\n",
    "        for i in range(len(df_final)):\n",
    "            if df_final['score_final'][i]<=t1:\n",
    "                newcatfinal.append(1)\n",
    "            elif df_final['score_final'][i]<=t2:\n",
    "                newcatfinal.append(2)\n",
    "            else:\n",
    "                newcatfinal.append(3)\n",
    "        df_final['category_final']=newcatfinal\n",
    "        print(temper, t1, t2, 'score_final t1 t2')\n",
    "        t1_gpt=t1\n",
    "        t2_gpt=t2\n",
    "\n",
    "        ###################\n",
    "        \n",
    "        \n",
    "\n",
    "        framingham_cat=[]\n",
    "        for i in range(len(df_final)):\n",
    "            if df_final['Framingham'][i]<=10:\n",
    "                framingham_cat.append(1)\n",
    "            elif df_final['Framingham'][i]<=20:\n",
    "                framingham_cat.append(2)\n",
    "            else:\n",
    "                framingham_cat.append(3)\n",
    "\n",
    "        df_final['framingham_cat']=framingham_cat\n",
    "\n",
    "        ACC_AHA_cat=[]\n",
    "        for i in range(len(df_final)):\n",
    "            if df_final['ACC/AHA'][i]<=7.5:\n",
    "                ACC_AHA_cat.append(1)\n",
    "            elif df_final['ACC/AHA'][i]<=20:\n",
    "                ACC_AHA_cat.append(2)\n",
    "            else:\n",
    "                ACC_AHA_cat.append(3)\n",
    "\n",
    "        df_final['ACC_AHA_cat']=ACC_AHA_cat\n",
    "\n",
    "        scorefinallist=list(df_final['Framingham'])\n",
    "        t1=np.percentile(scorefinallist,100/3)\n",
    "        t2=np.percentile(scorefinallist,200/3)\n",
    "        newcatfinal=[]\n",
    "        t1=10\n",
    "        t2=20\n",
    "        for i in range(len(df_final)):\n",
    "            if df_final['Framingham'][i]<=t1:\n",
    "                newcatfinal.append(1)\n",
    "            elif df_final['Framingham'][i]<=t2:\n",
    "                newcatfinal.append(2)\n",
    "            else:\n",
    "                newcatfinal.append(3)\n",
    "        df_final['framingham_cat']=newcatfinal\n",
    "        print(temper, t1, t2, 'framingham t1 t2')\n",
    "        t1_fram=t1\n",
    "        t2_fram=t2\n",
    "\n",
    "        scorefinallist=list(df_final['ACC/AHA'])\n",
    "        t1=np.percentile(scorefinallist,100/3)\n",
    "        t2=np.percentile(scorefinallist,200/3)\n",
    "        newcatfinal=[]\n",
    "        t1=7.5\n",
    "        t2=20\n",
    "        for i in range(len(df_final)):\n",
    "            if df_final['ACC/AHA'][i]<=t1:\n",
    "                newcatfinal.append(1)\n",
    "            elif df_final['ACC/AHA'][i]<=t2:\n",
    "                newcatfinal.append(2)\n",
    "            else:\n",
    "                newcatfinal.append(3)\n",
    "        df_final['ACC_AHA_cat']=newcatfinal\n",
    "        print(temper, t1, t2, 'PCE t1 t2')\n",
    "        t1_PCE=t1\n",
    "        t2_PCE=t2\n",
    "\n",
    "        t1list=[t1_gpt,t1_fram,t1_PCE]\n",
    "        t2list=[t2_gpt,t2_fram,t2_PCE]\n",
    "\n",
    "        t1t2df=pd.DataFrame({'t1':t1list,'t2':t2list})\n",
    "        t1t2df.index=['gpt','framingham','PCE']\n",
    "        t1t2df.to_csv(newtablename+'/t1t2.csv')\n",
    "\n",
    "\n",
    "        score1list=list(df_final['score_final'])\n",
    "        score2list=list(df_final['Framingham'])\n",
    "        score3list=list(df_final['ACC/AHA'])\n",
    "\n",
    "        score1list.sort()\n",
    "        score2list.sort()\n",
    "        score3list.sort()\n",
    "\n",
    "        score1_newcat=[]\n",
    "        score2_newcat=[]\n",
    "        score3_newcat=[]\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(len(df_final)):\n",
    "            if df_final['score_final'][i]<score1list[round(upto*0.6)]:\n",
    "                score1_newcat.append(1)\n",
    "            elif df_final['score_final'][i]<score1list[round(upto*0.9)]:\n",
    "                score1_newcat.append(2)\n",
    "            else:\n",
    "                score1_newcat.append(3)\n",
    "\n",
    "            if df_final['Framingham'][i]<score2list[round(upto*0.6)]:\n",
    "                score2_newcat.append(1)\n",
    "            elif df_final['Framingham'][i]<score2list[round(upto*0.9)]:\n",
    "                score2_newcat.append(2)\n",
    "            else:\n",
    "                score2_newcat.append(3)\n",
    "\n",
    "            if df_final['ACC/AHA'][i]<score3list[round(upto*0.6)]:\n",
    "                score3_newcat.append(1)\n",
    "            elif df_final['ACC/AHA'][i]<score3list[round(upto*0.9)]:\n",
    "                score3_newcat.append(2)\n",
    "            else:\n",
    "                score3_newcat.append(3)\n",
    "\n",
    "        df_final['score1_newcat']=score1_newcat\n",
    "        df_final['score2_newcat']=score2_newcat\n",
    "        df_final['score3_newcat']=score3_newcat\n",
    "\n",
    "        cutofftxt+= 'allcausemortality, ChatGPT_score, 0.6, 0.9\\n'\n",
    "        cutofftxt+= (str(round(score1list[round(upto*0.6)],1)) + '\\n')\n",
    "        cutofftxt+= (str(round(score1list[round(upto*0.9)],1)) + '\\n')\n",
    "        cutofftxt+= 'allcausemortality, Framingham, 0.6, 0.9\\n'\n",
    "        cutofftxt+= (str(round(score2list[round(upto*0.6)],1)) + '\\n')\n",
    "        cutofftxt+= (str(round(score2list[round(upto*0.9)],1)) + '\\n')\n",
    "        cutofftxt+= 'allcausemortality, ACC/AHA, 0.6, 0.9\\n'\n",
    "        cutofftxt+= (str(round(score3list[round(upto*0.6)],1)) + '\\n')\n",
    "        cutofftxt+= (str(round(score3list[round(upto*0.9)],1)) + '\\n')\n",
    "\n",
    "\n",
    "        df_final_temp=df_final[df_final['datediff_algo_int2']<=3650]\n",
    "        df_final_temp=df_final_temp[df_final_temp['datediff_algo_int2']>=0]\n",
    "        df_final_temp.reset_index(inplace=True,drop=True)\n",
    "        score1list=list(df_final_temp['score_final'])\n",
    "        score2list=list(df_final_temp['Framingham'])\n",
    "        score3list=list(df_final_temp['ACC/AHA'])\n",
    "\n",
    "        score1list.sort()\n",
    "        score2list.sort()\n",
    "        score3list.sort()\n",
    "\n",
    "        score1_newcat=[]\n",
    "        score2_newcat=[]\n",
    "        score3_newcat=[]\n",
    "\n",
    "        for i in range(len(df_final_temp)):\n",
    "            if df_final_temp['score_final'][i]<score1list[round(upto*0.6)]:\n",
    "                score1_newcat.append(1)\n",
    "            elif df_final_temp['score_final'][i]<score1list[round(upto*0.9)]:\n",
    "                score1_newcat.append(2)\n",
    "            else:\n",
    "                score1_newcat.append(3)\n",
    "\n",
    "            if df_final_temp['Framingham'][i]<score2list[round(upto*0.6)]:\n",
    "                score2_newcat.append(1)\n",
    "            elif df_final_temp['Framingham'][i]<score2list[round(upto*0.9)]:\n",
    "                score2_newcat.append(2)\n",
    "            else:\n",
    "                score2_newcat.append(3)\n",
    "\n",
    "            if df_final_temp['ACC/AHA'][i]<score3list[round(upto*0.6)]:\n",
    "                score3_newcat.append(1)\n",
    "            elif df_final_temp['ACC/AHA'][i]<score3list[round(upto*0.9)]:\n",
    "                score3_newcat.append(2)\n",
    "            else:\n",
    "                score3_newcat.append(3)\n",
    "\n",
    "        df_final_temp['score1_newcat_algoMACE']=score1_newcat\n",
    "        df_final_temp['score2_newcat_algoMACE']=score2_newcat\n",
    "        df_final_temp['score3_newcat_algoMACE']=score3_newcat\n",
    "        df_final_temp=df_final_temp[['eid','score1_newcat_algoMACE','score2_newcat_algoMACE','score3_newcat_algoMACE']]\n",
    "        df_final=pd.merge(df_final, df_final_temp, left_on='eid', right_on='eid', how='left')\n",
    "\n",
    "\n",
    "        cutofftxt+= 'algoMACE, ChatGPT_score, 0.6, 0.9\\n'\n",
    "        cutofftxt+= (str(round(score1list[round(upto*0.6)],1)) + '\\n')\n",
    "        cutofftxt+= (str(round(score1list[round(upto*0.9)],1)) + '\\n')\n",
    "        cutofftxt+= 'algoMACE, Framingham, 0.6, 0.9\\n'\n",
    "        cutofftxt+= (str(round(score2list[round(upto*0.6)],1)) + '\\n')\n",
    "        cutofftxt+= (str(round(score2list[round(upto*0.9)],1)) + '\\n')\n",
    "        cutofftxt+= 'algoMACE, ACC/AHA, 0.6, 0.9\\n'\n",
    "        cutofftxt+= (str(round(score3list[round(upto*0.6)],1)) + '\\n')\n",
    "        cutofftxt+= (str(round(score3list[round(upto*0.9)],1)) + '\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        df_final_temp=df_final[df_final['datediff_firstoccur_int2']<=3650]\n",
    "        df_final_temp=df_final_temp[df_final_temp['datediff_firstoccur_int2']>=0]\n",
    "        df_final_temp.reset_index(inplace=True,drop=True)\n",
    "\n",
    "        score1list=list(df_final_temp['score_final'])\n",
    "        score2list=list(df_final_temp['Framingham'])\n",
    "        score3list=list(df_final_temp['ACC/AHA'])\n",
    "\n",
    "        score1list.sort()\n",
    "        score2list.sort()\n",
    "        score3list.sort()\n",
    "\n",
    "        score1_newcat=[]\n",
    "        score2_newcat=[]\n",
    "        score3_newcat=[]\n",
    "\n",
    "        for i in range(len(df_final_temp)):\n",
    "            if df_final_temp['score_final'][i]<score1list[round(upto*0.6)]:\n",
    "                score1_newcat.append(1)\n",
    "            elif df_final_temp['score_final'][i]<score1list[round(upto*0.9)]:\n",
    "                score1_newcat.append(2)\n",
    "            else:\n",
    "                score1_newcat.append(3)\n",
    "\n",
    "            if df_final_temp['Framingham'][i]<score2list[round(upto*0.6)]:\n",
    "                score2_newcat.append(1)\n",
    "            elif df_final_temp['Framingham'][i]<score2list[round(upto*0.9)]:\n",
    "                score2_newcat.append(2)\n",
    "            else:\n",
    "                score2_newcat.append(3)\n",
    "\n",
    "            if df_final_temp['ACC/AHA'][i]<score3list[round(upto*0.6)]:\n",
    "                score3_newcat.append(1)\n",
    "            elif df_final_temp['ACC/AHA'][i]<score3list[round(upto*0.9)]:\n",
    "                score3_newcat.append(2)\n",
    "            else:\n",
    "                score3_newcat.append(3)\n",
    "\n",
    "        df_final_temp['score1_newcat_firstoccurMACE']=score1_newcat\n",
    "        df_final_temp['score2_newcat_firstoccurMACE']=score2_newcat\n",
    "        df_final_temp['score3_newcat_firstoccurMACE']=score3_newcat\n",
    "        df_final_temp=df_final_temp[['eid','score1_newcat_firstoccurMACE','score2_newcat_firstoccurMACE','score3_newcat_firstoccurMACE']]\n",
    "        df_final=pd.merge(df_final, df_final_temp, left_on='eid', right_on='eid', how='left')\n",
    "\n",
    "        cutofftxt+= 'firstoccurMACE, ChatGPT_score, 0.6, 0.9\\n'\n",
    "        cutofftxt+= (str(round(score1list[round(upto*0.6)],1)) + '\\n')\n",
    "        cutofftxt+= (str(round(score1list[round(upto*0.9)],1)) + '\\n')\n",
    "        cutofftxt+= 'firstoccurMACE, Framingham, 0.6, 0.9\\n'\n",
    "        cutofftxt+= (str(round(score2list[round(upto*0.6)],1)) + '\\n')\n",
    "        cutofftxt+= (str(round(score2list[round(upto*0.9)],1)) + '\\n')\n",
    "        cutofftxt+= 'firstoccurMACE, ACC/AHA, 0.6, 0.9\\n'\n",
    "        cutofftxt+= (str(round(score3list[round(upto*0.6)],1)) + '\\n')\n",
    "        cutofftxt+= (str(round(score3list[round(upto*0.9)],1)) + '\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            os.mkdir(newtablename)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        file = open(newtablename+\"/samplenumber.txt\", \"w\") \n",
    "        file.write(txt)\n",
    "        file.close()\n",
    "\n",
    "        file = open(newtablename+\"/60percent90percent_cutoffs.txt\", \"w\") \n",
    "        file.write(cutofftxt)\n",
    "        file.close()\n",
    "\n",
    "        #df_final=df_final.dropna(subset='score0',axis=0)\n",
    "        #df_final.reset_index(inplace=True,drop=True)\n",
    "\n",
    "\n",
    "        ######## 설정변수 ##########\n",
    "        ylim1_survival_allcausemortality=0.86\n",
    "        ylim2_survival_allcausemortality=1.01\n",
    "        ylim1_survival_algoMACE=0.90\n",
    "        ylim2_survival_algoMACE=1.01\n",
    "        ylim1_survival_firstoccurMACE=0.78\n",
    "        ylim2_survival_firstoccurMACE=1.01\n",
    "\n",
    "\n",
    "        ############################\n",
    "        txt=''\n",
    "        txt_men_40=''\n",
    "        txt_women_40=''\n",
    "        txt_men_50=''\n",
    "        txt_women_50=''\n",
    "        txt_men_60=''\n",
    "        txt_women_60=''\n",
    "        txt_men_allages=''\n",
    "        txt_women_allages=''\n",
    "        txt_bothsex_40=''\n",
    "        txt_bothsex_50=''\n",
    "        txt_bothsex_60=''\n",
    "\n",
    "        catnamedict={}\n",
    "        catnamedict['ChatGPT (Original)']='category_final'\n",
    "        catnamedict['ChatGPT (6:3:1)']='score1_newcat'\n",
    "        catnamedict['Framingham (Original)']='framingham_cat'\n",
    "        catnamedict['Framingham (6:3:1)']='score2_newcat'\n",
    "        catnamedict['ACC/AHA ASCVD (Original)']='ACC_AHA_cat'\n",
    "        catnamedict['ACC/AHA ASCVD (6:3:1)']='score3_newcat'\n",
    "\n",
    "        scorenamedict={}\n",
    "        scorenamedict['ChatGPT (Original)']='score_final'\n",
    "        #scorenamedict['ChatGPT (Original)']='score0'\n",
    "        scorenamedict['ChatGPT (6:3:1)']='score_final'\n",
    "        scorenamedict['Framingham (Original)']='Framingham'\n",
    "        scorenamedict['Framingham (6:3:1)']='Framingham'\n",
    "        scorenamedict['ACC/AHA ASCVD (Original)']='ACC/AHA'\n",
    "        scorenamedict['ACC/AHA ASCVD (6:3:1)']='ACC/AHA'\n",
    "\n",
    "        outcome_event_dict={}\n",
    "        outcome_event_dict['allcausemortality']='event'\n",
    "        outcome_event_dict['algoMACE']='algo_event'\n",
    "        outcome_event_dict['firstoccurMACE']='firstoccur_event'\n",
    "\n",
    "        outcome_datediff_dict={}\n",
    "        outcome_datediff_dict['allcausemortality']='datediff_int2'\n",
    "        outcome_datediff_dict['algoMACE']='datediff_algo_int2'\n",
    "        outcome_datediff_dict['firstoccurMACE']='datediff_firstoccur_int2'\n",
    "\n",
    "        ylim1_dict={}\n",
    "        ylim1_dict['allcausemortality']=ylim1_survival_allcausemortality\n",
    "        ylim1_dict['algoMACE']=ylim1_survival_algoMACE\n",
    "        ylim1_dict['firstoccurMACE']=ylim1_survival_firstoccurMACE\n",
    "\n",
    "        ylim2_dict={}\n",
    "        ylim2_dict['allcausemortality']=ylim2_survival_allcausemortality\n",
    "        ylim2_dict['algoMACE']=ylim2_survival_algoMACE\n",
    "        ylim2_dict['firstoccurMACE']=ylim2_survival_firstoccurMACE\n",
    "\n",
    "        def survivalgraph(catname1,catname2,outcome,ylim1,ylim2):\n",
    "            global txt\n",
    "            global txt_men_40\n",
    "            global txt_men_50\n",
    "            global txt_men_60\n",
    "            global txt_women_40\n",
    "            global txt_women_50\n",
    "            global txt_women_60\n",
    "            global txt_bothsex_40\n",
    "            global txt_bothsex_50\n",
    "            global txt_bothsex_60\n",
    "            global txt_men_allages\n",
    "            global txt_women_allages\n",
    "            datediff_temp=outcome_datediff_dict[outcome]\n",
    "            event_temp=outcome_event_dict[outcome]\n",
    "            score_temp=scorenamedict[catname1]\n",
    "\n",
    "            df_final_temp=df_final[df_final[datediff_temp]<=3650][['age','sex',catname2,datediff_temp,event_temp,score_temp]]\n",
    "            df_final_temp=df_final_temp[df_final_temp[datediff_temp]>=0]\n",
    "\n",
    "            #df_final_temp2=df_final_temp[[event_temp,score_temp]]\n",
    "            #print(len(df_final_temp2))\n",
    "            #df_final_temp2=df_final_temp2.dropna()\n",
    "            #fpr,tpr,thres=roc_curve(df_final_temp2[event_temp],df_final_temp2[score_temp])\n",
    "            #roc_auc = round(auc(fpr, tpr),3)\n",
    "            #print(len(df_final_temp2),np.sum(df_final_temp2[event_temp]),roc_auc)\n",
    "\n",
    "            fpr,tpr,thres=roc_curve(df_final_temp[event_temp],df_final_temp[score_temp])\n",
    "            roc_auc = round(auc(fpr, tpr),3)\n",
    "\n",
    "            df_final_temp_men_40=df_final_temp[df_final_temp['age']>=40]\n",
    "            df_final_temp_men_40=df_final_temp_men_40[df_final_temp_men_40['age']<50]\n",
    "            df_final_temp_men_40=df_final_temp_men_40[df_final_temp_men_40['sex']==1]\n",
    "            df_final_temp_men_40.reset_index(inplace=True,drop=True)\n",
    "\n",
    "            df_final_temp_men_50=df_final_temp[df_final_temp['age']>=50]\n",
    "            df_final_temp_men_50=df_final_temp_men_50[df_final_temp_men_50['age']<60]\n",
    "            df_final_temp_men_50=df_final_temp_men_50[df_final_temp_men_50['sex']==1]\n",
    "            df_final_temp_men_50.reset_index(inplace=True,drop=True)\n",
    "\n",
    "            df_final_temp_men_60=df_final_temp[df_final_temp['age']>=60]\n",
    "            df_final_temp_men_60=df_final_temp_men_60[df_final_temp_men_60['age']<71]\n",
    "            df_final_temp_men_60=df_final_temp_men_60[df_final_temp_men_60['sex']==1]\n",
    "            df_final_temp_men_60.reset_index(inplace=True,drop=True)\n",
    "\n",
    "            df_final_temp_women_40=df_final_temp[df_final_temp['age']>=40]\n",
    "            df_final_temp_women_40=df_final_temp_women_40[df_final_temp_women_40['age']<50]\n",
    "            df_final_temp_women_40=df_final_temp_women_40[df_final_temp_women_40['sex']==0]\n",
    "            df_final_temp_women_40.reset_index(inplace=True,drop=True)\n",
    "\n",
    "            df_final_temp_women_50=df_final_temp[df_final_temp['age']>=50]\n",
    "            df_final_temp_women_50=df_final_temp_women_50[df_final_temp_women_50['age']<60]\n",
    "            df_final_temp_women_50=df_final_temp_women_50[df_final_temp_women_50['sex']==0]\n",
    "            df_final_temp_women_50.reset_index(inplace=True,drop=True)\n",
    "\n",
    "            df_final_temp_women_60=df_final_temp[df_final_temp['age']>=60]\n",
    "            df_final_temp_women_60=df_final_temp_women_60[df_final_temp_women_60['age']<71]\n",
    "            df_final_temp_women_60=df_final_temp_women_60[df_final_temp_women_60['sex']==0]\n",
    "            df_final_temp_women_60.reset_index(inplace=True,drop=True)\n",
    "\n",
    "            df_final_temp_bothsex_40=df_final_temp[df_final_temp['age']>=40]\n",
    "            df_final_temp_bothsex_40=df_final_temp_bothsex_40[df_final_temp_bothsex_40['age']<50]\n",
    "            df_final_temp_bothsex_40.reset_index(inplace=True,drop=True)\n",
    "\n",
    "            df_final_temp_bothsex_50=df_final_temp[df_final_temp['age']>=50]\n",
    "            df_final_temp_bothsex_50=df_final_temp_bothsex_50[df_final_temp_bothsex_50['age']<60]\n",
    "            df_final_temp_bothsex_50.reset_index(inplace=True,drop=True)\n",
    "\n",
    "            df_final_temp_bothsex_60=df_final_temp[df_final_temp['age']>=60]\n",
    "            df_final_temp_bothsex_60=df_final_temp_bothsex_60[df_final_temp_bothsex_60['age']<71]\n",
    "            df_final_temp_bothsex_60.reset_index(inplace=True,drop=True)\n",
    "\n",
    "            df_final_temp_men_allages=df_final_temp[df_final_temp['sex']==1]\n",
    "            df_final_temp_men_allages.reset_index(inplace=True,drop=True)\n",
    "\n",
    "            df_final_temp_women_allages=df_final_temp[df_final_temp['sex']==0]\n",
    "            df_final_temp_women_allages.reset_index(inplace=True,drop=True)\n",
    "\n",
    "            fpr,tpr,thres=roc_curve(df_final_temp_men_40[event_temp],df_final_temp_men_40[score_temp])\n",
    "            roc_auc_men_40 = round(auc(fpr, tpr),3)\n",
    "\n",
    "            fpr,tpr,thres=roc_curve(df_final_temp_men_50[event_temp],df_final_temp_men_50[score_temp])\n",
    "            roc_auc_men_50 = round(auc(fpr, tpr),3)\n",
    "\n",
    "            fpr,tpr,thres=roc_curve(df_final_temp_men_60[event_temp],df_final_temp_men_60[score_temp])\n",
    "            roc_auc_men_60 = round(auc(fpr, tpr),3)\n",
    "\n",
    "            fpr,tpr,thres=roc_curve(df_final_temp_women_40[event_temp],df_final_temp_women_40[score_temp])\n",
    "            roc_auc_women_40 = round(auc(fpr, tpr),3)\n",
    "\n",
    "            fpr,tpr,thres=roc_curve(df_final_temp_women_50[event_temp],df_final_temp_women_50[score_temp])\n",
    "            roc_auc_women_50 = round(auc(fpr, tpr),3)\n",
    "\n",
    "            fpr,tpr,thres=roc_curve(df_final_temp_women_60[event_temp],df_final_temp_women_60[score_temp])\n",
    "            roc_auc_women_60 = round(auc(fpr, tpr),3)\n",
    "\n",
    "            fpr,tpr,thres=roc_curve(df_final_temp_bothsex_40[event_temp],df_final_temp_bothsex_40[score_temp])\n",
    "            roc_auc_bothsex_40 = round(auc(fpr, tpr),3)\n",
    "\n",
    "            fpr,tpr,thres=roc_curve(df_final_temp_bothsex_50[event_temp],df_final_temp_bothsex_50[score_temp])\n",
    "            roc_auc_bothsex_50 = round(auc(fpr, tpr),3)\n",
    "\n",
    "            fpr,tpr,thres=roc_curve(df_final_temp_bothsex_60[event_temp],df_final_temp_bothsex_60[score_temp])\n",
    "            roc_auc_bothsex_60 = round(auc(fpr, tpr),3)\n",
    "\n",
    "            fpr,tpr,thres=roc_curve(df_final_temp_men_allages[event_temp],df_final_temp_men_allages[score_temp])\n",
    "            roc_auc_men_allages = round(auc(fpr, tpr),3)\n",
    "\n",
    "            fpr,tpr,thres=roc_curve(df_final_temp_women_allages[event_temp],df_final_temp_women_allages[score_temp])\n",
    "            roc_auc_women_allages = round(auc(fpr, tpr),3)\n",
    "\n",
    "\n",
    "\n",
    "            cat1 = df_final_temp[df_final_temp[catname2] == 1]\n",
    "            cat2 = df_final_temp[df_final_temp[catname2] == 2]\n",
    "            cat3 = df_final_temp[df_final_temp[catname2] == 3]\n",
    "            print(outcome,catname2, len(cat1),len(cat2),len(cat3))\n",
    "\n",
    "            kmf = KaplanMeierFitter()\n",
    "            kmf.fit(cat1[datediff_temp], cat1[event_temp], label='Low')\n",
    "            ax_kmf = kmf.plot(loc=slice(0.,3650.))\n",
    "            kmf.fit(cat2[datediff_temp], cat2[event_temp], label='Moderate')\n",
    "            ax_kmf = kmf.plot(ax = ax_kmf,loc=slice(0.,3650.))\n",
    "            kmf.fit(cat3[datediff_temp], cat3[event_temp], label='High')\n",
    "            ax_kmf = kmf.plot(ax = ax_kmf,loc=slice(0.,3650.))\n",
    "\n",
    "            ax_kmf.set_ylim([ylim1, ylim2])\n",
    "            ax_kmf.set_yticks(np.arange(ylim1, ylim2, step=0.02))\n",
    "            ax_kmf.set_xlabel('Time (days)')\n",
    "            ax_kmf.set_ylabel('Survival Rate')\n",
    "            ['ChatGPT (Original)','ChatGPT (6:3:1)','Framingham (Original)','Framingham (6:3:1)' ,'ACC/AHA ASCVD (Original)','ACC/AHA ASCVD (6:3:1)']\n",
    "            if catname1=='ChatGPT (Original)':\n",
    "                ax_kmf.set_title('GPT-4')\n",
    "            elif catname1=='Framingham (Original)':\n",
    "                ax_kmf.set_title('Framingham')\n",
    "            elif catname1=='ACC/AHA ASCVD (Original)':\n",
    "                ax_kmf.set_title('ACC/AHA')\n",
    "            else:\n",
    "                ax_kmf.set_title(catname1)\n",
    "\n",
    "\n",
    "\n",
    "            try:\n",
    "                os.mkdir(newtablename)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                os.mkdir(newtablename+'/survival')\n",
    "            except:\n",
    "                pass\n",
    "            catname1_temp=catname1.replace(' ','_')\n",
    "            catname1_temp=catname1_temp.replace('(','_')\n",
    "            catname1_temp=catname1_temp.replace(')','')\n",
    "            catname1_temp=catname1_temp.replace(':','')\n",
    "            catname1_temp=catname1_temp.replace('/','')\n",
    "            ax_kmf.get_figure().savefig(newtablename+\"/survival/\"+outcome+'_' +catname1_temp+   \".png\",transparent=True)\n",
    "            plt.close('all')\n",
    "\n",
    "            if catname1=='ChatGPT (Original)':\n",
    "                txt+= ('ChatGPT' + ' AUROC = ' + str(roc_auc) +'\\n' )\n",
    "                txt_men_40+= ('ChatGPT' + ' AUROC = ' + str(roc_auc_men_40) +'\\n' )\n",
    "                txt_men_50+= ('ChatGPT' + ' AUROC = ' + str(roc_auc_men_50) +'\\n' )\n",
    "                txt_men_60+= ('ChatGPT' + ' AUROC = ' + str(roc_auc_men_60) +'\\n' )\n",
    "                txt_women_40+= ('ChatGPT' + ' AUROC = ' + str(roc_auc_women_40) +'\\n' )\n",
    "                txt_women_50+= ('ChatGPT' + ' AUROC = ' + str(roc_auc_women_50) +'\\n' )\n",
    "                txt_women_60+= ('ChatGPT' + ' AUROC = ' + str(roc_auc_women_60) +'\\n' )\n",
    "                txt_bothsex_40+= ('ChatGPT' + ' AUROC = ' + str(roc_auc_bothsex_40) +'\\n' )\n",
    "                txt_bothsex_50+= ('ChatGPT' + ' AUROC = ' + str(roc_auc_bothsex_50) +'\\n' )\n",
    "                txt_bothsex_60+= ('ChatGPT' + ' AUROC = ' + str(roc_auc_bothsex_60) +'\\n' )\n",
    "                txt_men_allages+= ('ChatGPT' + ' AUROC = ' + str(roc_auc_men_allages) +'\\n' )\n",
    "                txt_women_allages+= ('ChatGPT' + ' AUROC = ' + str(roc_auc_women_allages) +'\\n' )\n",
    "            elif catname1=='Framingham (Original)':\n",
    "                txt+= ('Framingham' + ' AUROC = ' + str(roc_auc) +'\\n' )\n",
    "                txt_men_40+= ('Framingham' + ' AUROC = ' + str(roc_auc_men_40) +'\\n' )\n",
    "                txt_men_50+= ('Framingham' + ' AUROC = ' + str(roc_auc_men_50) +'\\n' )\n",
    "                txt_men_60+= ('Framingham' + ' AUROC = ' + str(roc_auc_men_60) +'\\n' )\n",
    "                txt_women_40+= ('Framingham' + ' AUROC = ' + str(roc_auc_women_40) +'\\n' )\n",
    "                txt_women_50+= ('Framingham' + ' AUROC = ' + str(roc_auc_women_50) +'\\n' )\n",
    "                txt_women_60+= ('Framingham' + ' AUROC = ' + str(roc_auc_women_60) +'\\n' )\n",
    "                txt_bothsex_40+= ('Framingham' + ' AUROC = ' + str(roc_auc_bothsex_40) +'\\n' )\n",
    "                txt_bothsex_50+= ('Framingham' + ' AUROC = ' + str(roc_auc_bothsex_50) +'\\n' )\n",
    "                txt_bothsex_60+= ('Framingham' + ' AUROC = ' + str(roc_auc_bothsex_60) +'\\n' )\n",
    "                txt_men_allages+= ('Framingham' + ' AUROC = ' + str(roc_auc_men_allages) +'\\n' )\n",
    "                txt_women_allages+= ('Framingham' + ' AUROC = ' + str(roc_auc_women_allages) +'\\n' )\n",
    "            elif catname1=='ACC/AHA ASCVD (Original)':\n",
    "                txt+= ('ACC/AHA' + ' AUROC = ' + str(roc_auc) +'\\n' )\n",
    "                txt_men_40+= ('ACC/AHA' + ' AUROC = ' + str(roc_auc_men_40) +'\\n' )\n",
    "                txt_men_50+= ('ACC/AHA' + ' AUROC = ' + str(roc_auc_men_50) +'\\n' )\n",
    "                txt_men_60+= ('ACC/AHA' + ' AUROC = ' + str(roc_auc_men_60) +'\\n' )\n",
    "                txt_women_40+= ('ACC/AHA' + ' AUROC = ' + str(roc_auc_women_40) +'\\n' )\n",
    "                txt_women_50+= ('ACC/AHA' + ' AUROC = ' + str(roc_auc_women_50) +'\\n' )\n",
    "                txt_women_60+= ('ACC/AHA' + ' AUROC = ' + str(roc_auc_women_60) +'\\n' )\n",
    "                txt_bothsex_40+= ('ACC/AHA' + ' AUROC = ' + str(roc_auc_bothsex_40) +'\\n' )\n",
    "                txt_bothsex_50+= ('ACC/AHA' + ' AUROC = ' + str(roc_auc_bothsex_50) +'\\n' )\n",
    "                txt_bothsex_60+= ('ACC/AHA' + ' AUROC = ' + str(roc_auc_bothsex_60) +'\\n' )\n",
    "                txt_men_allages+= ('ACC/AHA' + ' AUROC = ' + str(roc_auc_men_allages) +'\\n' )\n",
    "                txt_women_allages+= ('ACC/AHA' + ' AUROC = ' + str(roc_auc_women_allages) +'\\n' )\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for outcome in ['allcausemortality','algoMACE','firstoccurMACE']:\n",
    "            count=0\n",
    "            for catname1 in ['ChatGPT (Original)','ChatGPT (6:3:1)','Framingham (Original)','Framingham (6:3:1)' ,'ACC/AHA ASCVD (Original)','ACC/AHA ASCVD (6:3:1)']:\n",
    "                if count==0:\n",
    "                    txt+='===== ' +outcome+' ====='+'\\n'\n",
    "                    txt_men_40+='===== ' +outcome+' ====='+'\\n'\n",
    "                    txt_men_50+='===== ' +outcome+' ====='+'\\n'\n",
    "                    txt_men_60+='===== ' +outcome+' ====='+'\\n'\n",
    "                    txt_women_40+='===== ' +outcome+' ====='+'\\n'\n",
    "                    txt_women_50+='===== ' +outcome+' ====='+'\\n'\n",
    "                    txt_women_60+='===== ' +outcome+' ====='+'\\n'\n",
    "                    txt_bothsex_40+='===== ' +outcome+' ====='+'\\n'\n",
    "                    txt_bothsex_50+='===== ' +outcome+' ====='+'\\n'\n",
    "                    txt_bothsex_60+='===== ' +outcome+' ====='+'\\n'\n",
    "                    txt_men_allages+='===== ' +outcome+' ====='+'\\n'\n",
    "                    txt_women_allages+='===== ' +outcome+' ====='+'\\n'\n",
    "                    count+=1\n",
    "\n",
    "                ylim1_survival=ylim1_dict[outcome]\n",
    "                ylim2_survival=ylim2_dict[outcome]\n",
    "                catname2=catnamedict[catname1]\n",
    "                survivalgraph(catname1,catname2,outcome,ylim1_survival,ylim2_survival)\n",
    "\n",
    "\n",
    "        file = open(newtablename+\"/AUROC.txt\", \"w\") \n",
    "        file.write(txt)\n",
    "        file.close()\n",
    "\n",
    "        file = open(newtablename+\"/AUROC_men_40.txt\", \"w\") \n",
    "        file.write(txt_men_40)\n",
    "        file.close()\n",
    "\n",
    "        file = open(newtablename+\"/AUROC_men_50.txt\", \"w\") \n",
    "        file.write(txt_men_50)\n",
    "        file.close()\n",
    "\n",
    "        file = open(newtablename+\"/AUROC_men_60.txt\", \"w\") \n",
    "        file.write(txt_men_60)\n",
    "        file.close()\n",
    "\n",
    "        file = open(newtablename+\"/AUROC_women_40.txt\", \"w\") \n",
    "        file.write(txt_women_40)\n",
    "        file.close()\n",
    "\n",
    "        file = open(newtablename+\"/AUROC_women_50.txt\", \"w\") \n",
    "        file.write(txt_women_50)\n",
    "        file.close()\n",
    "\n",
    "        file = open(newtablename+\"/AUROC_women_60.txt\", \"w\") \n",
    "        file.write(txt_women_60)\n",
    "        file.close()\n",
    "\n",
    "        file = open(newtablename+\"/AUROC_bothsex_40.txt\", \"w\") \n",
    "        file.write(txt_bothsex_40)\n",
    "        file.close()\n",
    "\n",
    "        file = open(newtablename+\"/AUROC_bothsex_50.txt\", \"w\") \n",
    "        file.write(txt_bothsex_50)\n",
    "        file.close()\n",
    "\n",
    "        file = open(newtablename+\"/AUROC_bothsex_60.txt\", \"w\") \n",
    "        file.write(txt_bothsex_60)\n",
    "        file.close()\n",
    "\n",
    "        file = open(newtablename+\"/AUROC_men_allages.txt\", \"w\") \n",
    "        file.write(txt_men_allages)\n",
    "        file.close()\n",
    "\n",
    "        file = open(newtablename+\"/AUROC_women_allages.txt\", \"w\") \n",
    "        file.write(txt_women_allages)\n",
    "        file.close()\n",
    "\n",
    "        ######## 설정변수 ##########\n",
    "        lim=80\n",
    "\n",
    "\n",
    "        ############################\n",
    "\n",
    "\n",
    "        txt=''\n",
    "\n",
    "        def scatter_plot(xxx,yyy,lim):\n",
    "            global txt\n",
    "            plt.figure(figsize=(10,10))\n",
    "            if xxx=='ChatGPT':\n",
    "                xxxx='GPT-4'\n",
    "            else:\n",
    "                xxxx=xxx\n",
    "            if yyy=='ACC/AHA':\n",
    "                yyyy='ACC/AHA'\n",
    "            else:\n",
    "                yyyy=yyy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            plt.title(xxxx+ ' VS '+ yyyy , fontsize=20)\n",
    "\n",
    "            if xxx=='ChatGPT':\n",
    "                plt.xlabel('GPT-4', fontsize=14)\n",
    "            else:\n",
    "                plt.xlabel(xxx, fontsize=14)\n",
    "            if yyy=='ACC/AHA':\n",
    "                plt.ylabel('ACC/AHA', fontsize=14)\n",
    "            else:\n",
    "                plt.ylabel(yyy, fontsize=14)\n",
    "\n",
    "            plt.xlim([-5, lim])\n",
    "            plt.ylim([-5, lim])\n",
    "            plt.yticks(np.arange(0, lim+10, step=10))\n",
    "            plt.xticks(np.arange(0, lim+10, step=10))\n",
    "            if xxx=='ChatGPT':\n",
    "                xxx_column='score_final'\n",
    "            elif xxx=='Framingham':\n",
    "                xxx_column='Framingham'\n",
    "            elif xxx=='ACC/AHA':\n",
    "                xxx_column='ACC/AHA'\n",
    "            else:\n",
    "                print('error')\n",
    "\n",
    "            if yyy=='ChatGPT':\n",
    "                yyy_column='score_final'\n",
    "            elif yyy=='Framingham':\n",
    "                yyy_column='Framingham'\n",
    "            elif yyy=='ACC/AHA':\n",
    "                yyy_column='ACC/AHA'\n",
    "            else:\n",
    "                print('error')    \n",
    "\n",
    "            try:\n",
    "                os.mkdir(newtablename)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                os.mkdir(newtablename+'/scatter')\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            xxx=xxx.replace('/','_')\n",
    "            yyy=yyy.replace('/','_')\n",
    "\n",
    "            plt.scatter(df_final[xxx_column],df_final[yyy_column],s=0.08, alpha=0.8)\n",
    "            plt.savefig(newtablename+\"/scatter/\"+xxx+'_'+yyy+\".png\",transparent=True)\n",
    "            plt.close('all')\n",
    "\n",
    "            pearr=round(pearsonr(df_final[xxx_column],df_final[yyy_column]).statistic,3)\n",
    "            pearp=round(pearsonr(df_final[xxx_column],df_final[yyy_column]).pvalue,3)\n",
    "\n",
    "            txt+='==========================\\n'\n",
    "            txt+=('--- '+xxx+ ' VS '+ yyy + ' ---'+'\\n')\n",
    "            txt+=('pearson r = ' + str(pearr)+', pearson pvalue = '+str(pearp)   + '\\n')\n",
    "            txt+=(   xxx +'_mean = '+ str(round(np.mean(df_final[xxx_column]),3))   + '\\n')\n",
    "            txt+=(   yyy +'_mean = '+ str(round(np.mean(df_final[yyy_column]),3))   + '\\n')\n",
    "            txt+=(   xxx +'_shapiro_pvalue = '+ str(round(shapiro(df_final[xxx_column]).pvalue,3))   + '\\n')\n",
    "            txt+=(   yyy +'_shapiro_pvalue = '+ str(round(shapiro(df_final[yyy_column]).pvalue,3))   + '\\n')\n",
    "            txt+=(   'mannwhitneyu_pvalue = '+ str(round(mwu(df_final[xxx_column],df_final[yyy_column]).pvalue,3))   + '\\n')\n",
    "\n",
    "\n",
    "\n",
    "        for xxx,yyy in [['ChatGPT','Framingham'],['ChatGPT','ACC/AHA'],['Framingham','ACC/AHA']]:\n",
    "            scatter_plot(xxx,yyy,lim)\n",
    "\n",
    "        txt+='=========================='\n",
    "\n",
    "        file = open(newtablename+\"/scatter/\"+'stats.txt', \"w\") \n",
    "        file.write(txt)\n",
    "        file.close()\n",
    "\n",
    "\n",
    "\n",
    "        #######################################################\n",
    "\n",
    "        print(list(df_final.columns))\n",
    "\n",
    "        score_individuals=[]\n",
    "        for sss in range(iterations):\n",
    "            score_individuals.append('score'+str(sss))\n",
    "        df_final_temp=df_final[df_final['datediff_algo_int2']<=3650]\n",
    "        df_final_temp=df_final_temp[df_final_temp['datediff_algo_int2']>=0]\n",
    "        df_final_temp.reset_index(inplace=True,drop=True)\n",
    "        Framingham_temp_algo=df_final_temp['Framingham']\n",
    "        df_final_temp_algo_scores=df_final_temp[score_individuals]\n",
    "\n",
    "        df_final_temp=df_final[df_final['datediff_firstoccur_int2']<=3650]\n",
    "        df_final_temp=df_final_temp[df_final_temp['datediff_firstoccur_int2']>=0]\n",
    "        df_final_temp.reset_index(inplace=True,drop=True)\n",
    "        Framingham_temp_firstoccur=df_final_temp['Framingham']\n",
    "        df_final_temp_firstoccur_scores=df_final_temp[score_individuals]\n",
    "\n",
    "        mean=df_final_temp_firstoccur_scores.mean(axis=1)\n",
    "        std=df_final_temp_firstoccur_scores.std(axis=1)\n",
    "        df_final_temp_firstoccur_scores['mean']=mean\n",
    "        df_final_temp_firstoccur_scores['std']=std\n",
    "        df_final_temp_firstoccur_scores['CV']=df_final_temp_firstoccur_scores['std']/df_final_temp_firstoccur_scores['mean']\n",
    "\n",
    "        df_final_temp_firstoccur_scores['upper']=df_final_temp_firstoccur_scores['mean']+df_final_temp_firstoccur_scores['std']\n",
    "        df_final_temp_firstoccur_scores['under']=df_final_temp_firstoccur_scores['mean']-df_final_temp_firstoccur_scores['std']\n",
    "        df_final_temp_firstoccur_scores['Framingham']=Framingham_temp_firstoccur\n",
    "\n",
    "\n",
    "        scorefinallist=list(df_final['score_final'])\n",
    "        t1=np.percentile(scorefinallist,100/3)\n",
    "        t2=np.percentile(scorefinallist,200/3)\n",
    "        t1=10\n",
    "        t2=20\n",
    "        newcatfinal=[]\n",
    "        for i in range(len(df_final)):\n",
    "            if df_final['score_final'][i]<=t1:\n",
    "                newcatfinal.append(1)\n",
    "            elif df_final['score_final'][i]<=t2:\n",
    "                newcatfinal.append(2)\n",
    "            else:\n",
    "                newcatfinal.append(3)\n",
    "        df_final['category_final']=newcatfinal\n",
    "        \n",
    "        \n",
    "        \n",
    "        df_final_temp_firstoccur_scores_low=df_final_temp_firstoccur_scores[df_final_temp_firstoccur_scores['mean']<=t1].reset_index(drop=True)\n",
    "        df_final_temp_firstoccur_scores_mod=df_final_temp_firstoccur_scores[df_final_temp_firstoccur_scores['mean']<=t2].reset_index(drop=True)\n",
    "        df_final_temp_firstoccur_scores_mod=df_final_temp_firstoccur_scores_mod[df_final_temp_firstoccur_scores_mod['mean']>t1].reset_index(drop=True)\n",
    "        df_final_temp_firstoccur_scores_hig=df_final_temp_firstoccur_scores[df_final_temp_firstoccur_scores['mean']>t2].reset_index(drop=True)\n",
    "\n",
    "        firstoccur_total_CV=np.mean(df_final_temp_firstoccur_scores['CV'])\n",
    "        firstoccur_total_sd=np.mean(df_final_temp_firstoccur_scores['std'])\n",
    "        firstoccur_low_CV=np.mean(df_final_temp_firstoccur_scores_low['CV'])\n",
    "        firstoccur_mod_CV=np.mean(df_final_temp_firstoccur_scores_mod['CV'])\n",
    "        firstoccur_hig_CV=np.mean(df_final_temp_firstoccur_scores_hig['CV'])\n",
    "        firstoccur_low_sd=np.mean(df_final_temp_firstoccur_scores_low['std'])\n",
    "        firstoccur_mod_sd=np.mean(df_final_temp_firstoccur_scores_mod['std'])\n",
    "        firstoccur_hig_sd=np.mean(df_final_temp_firstoccur_scores_hig['std'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        mean=df_final_temp_algo_scores.mean(axis=1)\n",
    "        std=df_final_temp_algo_scores.std(axis=1)\n",
    "        df_final_temp_algo_scores['mean']=mean\n",
    "        df_final_temp_algo_scores['std']=std\n",
    "        df_final_temp_algo_scores['CV']=df_final_temp_algo_scores['std']/df_final_temp_algo_scores['mean']\n",
    "\n",
    "        df_final_temp_algo_scores['upper']=df_final_temp_algo_scores['mean']+df_final_temp_algo_scores['std']\n",
    "        df_final_temp_algo_scores['under']=df_final_temp_algo_scores['mean']-df_final_temp_algo_scores['std']\n",
    "        df_final_temp_algo_scores['Framingham']=Framingham_temp_algo\n",
    "\n",
    "        df_final_temp_algo_scores_low=df_final_temp_algo_scores[df_final_temp_algo_scores['mean']<=t1].reset_index(drop=True)\n",
    "        df_final_temp_algo_scores_mod=df_final_temp_algo_scores[df_final_temp_algo_scores['mean']<=t2].reset_index(drop=True)\n",
    "        df_final_temp_algo_scores_mod=df_final_temp_algo_scores_mod[df_final_temp_algo_scores_mod['mean']>t1].reset_index(drop=True)\n",
    "        df_final_temp_algo_scores_hig=df_final_temp_algo_scores[df_final_temp_algo_scores['mean']>t2].reset_index(drop=True)\n",
    "\n",
    "        algo_total_CV=np.mean(df_final_temp_algo_scores['CV'])\n",
    "        algo_total_sd=np.mean(df_final_temp_algo_scores['std'])\n",
    "        algo_low_CV=np.mean(df_final_temp_algo_scores_low['CV'])\n",
    "        algo_mod_CV=np.mean(df_final_temp_algo_scores_mod['CV'])\n",
    "        algo_hig_CV=np.mean(df_final_temp_algo_scores_hig['CV'])\n",
    "        algo_low_sd=np.mean(df_final_temp_algo_scores_low['std'])\n",
    "        algo_mod_sd=np.mean(df_final_temp_algo_scores_mod['std'])\n",
    "        algo_hig_sd=np.mean(df_final_temp_algo_scores_hig['std'])\n",
    "\n",
    "        firstoccurcvsdlist=[firstoccur_total_CV,firstoccur_total_sd,firstoccur_low_CV,firstoccur_mod_CV,firstoccur_hig_CV,firstoccur_low_sd,firstoccur_mod_sd,firstoccur_hig_sd]\n",
    "        algocvsdlist=[algo_total_CV,algo_total_sd,algo_low_CV,algo_mod_CV,algo_hig_CV,algo_low_sd,algo_mod_sd,algo_hig_sd]\n",
    "\n",
    "\n",
    "        cvsddf=pd.DataFrame({'algo':algocvsdlist,'firstoccur':firstoccurcvsdlist})\n",
    "        cvsddf.index=['total_CV','total_SD','low_CV','mod_CV','high_CV','low_SD','mod_SD','high_SD']\n",
    "        cvsddf.to_csv(newtablename+'/CV_SD.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        df_final.to_csv('20230825_df_final_gpt4_50000_5iter_nottertile.csv',index=False)\n",
    "\n",
    "\n",
    "        #######################################################\n",
    "\n",
    "        df_final['BMI']=(df_final['weight']/(df_final['height']/100))/(df_final['height']/100)\n",
    "\n",
    "\n",
    "        dfdfdf2=df_final[['age','sex','total_chol','HDL','LDL','TG','SBP','DBP','BMI','Smoking','med_final','DM_final','Framingham','ACC/AHA','framingham_cat','ACC_AHA_cat','category_final','score_final','firstoccur_event']]\n",
    "        dfdfdf2.columns=['Age','Sex','Total_chol','HDL','LDL','TG','SBP','DBP','BMI','Smoking','BP medication','DM','Framingham','ACC/AHA','Framingham category','ACC/AHA category','ChatGPT category','ChatGPT score','firstoccur_event']\n",
    "\n",
    "        catcolumns=['Smoking','Sex','DM','BP medication','ChatGPT category','Framingham category','ACC/AHA category','firstoccur_event']\n",
    "\n",
    "        def table1(catcolumn):\n",
    "            nonnormallist=[]\n",
    "            def _normality(self, x):\n",
    "                #print(x.name)\n",
    "\n",
    "                if len(x.values[~np.isnan(x.values)]) >= 20:\n",
    "                    p = stats.shapiro(x.values).pvalue\n",
    "                else:\n",
    "                    p = None\n",
    "                # dropna=False argument in pivot_table does not function as expected\n",
    "                # return -1 instead of None\n",
    "                if pd.isnull(p):\n",
    "                    return -1\n",
    "                if p<=0.05:\n",
    "                    nonnormallist.append(x.name)\n",
    "                return p\n",
    "\n",
    "            TableOne._normality=_normality\n",
    "\n",
    "            def my_custom_test(group1, group2):\n",
    "                \"\"\"\n",
    "                Hypothesis test for test_self_defined_statistical_tests\n",
    "                \"\"\"\n",
    "                my_custom_test.__name__ = \"mannwhitneyu\"\n",
    "                _, pval= scipy.stats.mannwhitneyu(group1, group2)\n",
    "                return pval\n",
    "\n",
    "            nonnormallist=[]\n",
    "            def _normality(self, x):\n",
    "                #print(x.name)\n",
    "\n",
    "                if len(x.values[~np.isnan(x.values)]) >= 20:\n",
    "                    p = stats.shapiro(x.values).pvalue\n",
    "                else:\n",
    "                    p = None\n",
    "                # dropna=False argument in pivot_table does not function as expected\n",
    "                # return -1 instead of None\n",
    "                if pd.isnull(p):\n",
    "                    return -1\n",
    "                if p<=0.05:\n",
    "                    nonnormallist.append(x.name)\n",
    "                return p\n",
    "\n",
    "            TableOne._normality=_normality\n",
    "\n",
    "            table1=TableOne(dfdfdf2,categorical=catcolumns,groupby=[catcolumn],normal_test=True,pval=True,htest_name=True)\n",
    "            nonnormallist=list(set(nonnormallist))\n",
    "            nonnormallist\n",
    "\n",
    "            table1=TableOne(dfdfdf2,categorical=catcolumns,groupby=[catcolumn],normal_test=True,pval=True,htest_name=True,nonnormal=nonnormallist)\n",
    "            try:\n",
    "                os.mkdir(newtablename)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                os.mkdir(newtablename+'/table1')\n",
    "            except:\n",
    "                pass\n",
    "            catcolumn=catcolumn.replace(' ','_')\n",
    "            catcolumn=catcolumn.replace('/','_')\n",
    "            table1.to_html(newtablename+'/table1/'+catcolumn+'.html')\n",
    "\n",
    "        for catcolumn in ['ChatGPT category','Framingham category','ACC/AHA category']:\n",
    "            table1(catcolumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3abf472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3efd50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6ea6c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103ec931",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############################\n",
    "table_name=\"\" #enter table name\n",
    "iterations=5\n",
    "upto=50000\n",
    "############################\n",
    "\n",
    "for plusplus in range(1): \n",
    "    for temper in [0.4]:\n",
    "\n",
    "\n",
    "        txt=''\n",
    "\n",
    "        cutofftxt=''\n",
    "        for i in range(iterations):\n",
    "            newtablename=table_name + '_' + str(int(temper*10)) + '_' + str(i+plusplus)\n",
    "\n",
    "            sql_statement=\"select * from [\"+ newtablename + \"]\"\n",
    "            conn = pymssql.connect(host=r\"(local)\", database='WorkDB4', charset='utf8')\n",
    "            globals()['data{}'.format(i)] = pd.read_sql(sql=sql_statement, con=conn)\n",
    "            globals()['data{}'.format(i)]['rank_by_eid']=globals()['data{}'.format(i)].groupby('eid')['system'].rank(method='first')\n",
    "            globals()['data{}'.format(i)]=globals()['data{}'.format(i)][globals()['data{}'.format(i)]['rank_by_eid']==1]\n",
    "            globals()['data{}'.format(i)].reset_index(inplace=True,drop=True)\n",
    "            globals()['data{}'.format(i)].drop(['rank_by_eid'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "        for j in range(iterations):\n",
    "            dat=globals()['data{}'.format(j)]\n",
    "\n",
    "            eid=dat['eid']\n",
    "            score_gpt=dat['score']\n",
    "            category=dat['category']\n",
    "            score_framingham=dat['framingham']\n",
    "            score_acc_aha=dat['ACC_AHA']\n",
    "\n",
    "            score_gpt2=[]\n",
    "\n",
    "            for i in range(len(score_gpt)):\n",
    "                try:\n",
    "                    score_gpt2.append(float(re.findall(\"\\d+[.]\\d+[%]\",score_gpt[i])[0].split('%')[0]))\n",
    "                except:\n",
    "                    try:\n",
    "                        score_gpt2.append(float(re.findall(\"\\d+[%]\",score_gpt[i])[0].split('%')[0]))\n",
    "                    except:\n",
    "                        try:\n",
    "                            score_gpt2.append(float(re.findall(\"\\d+[.]\\d+\",score_gpt[i])[0]))\n",
    "                        except:\n",
    "                            try:\n",
    "                                score_gpt2.append(float(re.findall(\"\\d+\",score_gpt[i])[-1]))\n",
    "                            except:\n",
    "                                score_gpt2.append(float(dat['ACC_AHA'][i]))\n",
    "                                print(score_gpt[i],'====')\n",
    "\n",
    "\n",
    "            category2=[]\n",
    "            for i in range(len(score_gpt2)):\n",
    "                if np.isnan(score_gpt2[i])==False:\n",
    "                    if score_gpt2[i]>20:\n",
    "                        category2.append('High')\n",
    "                    elif score_gpt2[i]>10:\n",
    "                        category2.append('Moderate')\n",
    "                    else:\n",
    "                        category2.append('Low')\n",
    "                else:\n",
    "                    category2.append(np.nan)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            columnname_score='score'+str(j)\n",
    "            columnname_cat='category'+str(j)\n",
    "            globals()['data{}_1'.format(j)]=pd.DataFrame({'eid':eid,columnname_score:score_gpt2,columnname_cat:category2})\n",
    "            globals()['data{}_1'.format(j)]=globals()['data{}_1'.format(j)].dropna(axis=0)\n",
    "            globals()['data{}_1'.format(j)].reset_index(inplace=True,drop=True)\n",
    "\n",
    "        df2_0=df.iloc[:upto]\n",
    "\n",
    "        for i in range(iterations):\n",
    "            globals()['data{}_1'.format(i)] = globals()['data{}_1'.format(i)].astype({ 'eid' : 'int' })\n",
    "\n",
    "        for i in range(iterations):\n",
    "            globals()['df2_{}'.format(i+1)] = pd.merge(globals()['df2_{}'.format(i)], globals()['data{}_1'.format(i)], left_on='eid', right_on='eid', how='left')\n",
    "\n",
    "        globals()['df2_{}'.format(1)].drop_duplicates(inplace=True,ignore_index=True)\n",
    "        print(\"length\",len(globals()['df2_{}'.format(1)]))\n",
    "\n",
    "        for j in range(iterations):\n",
    "            globals()['category{}_int'.format(j)]=[]\n",
    "\n",
    "        for j in range(iterations):\n",
    "            columnname='category'+str(j)\n",
    "            for i in range(len(globals()['df2_{}'.format(iterations)])):\n",
    "                if globals()['df2_{}'.format(iterations)][columnname][i]=='Low':\n",
    "                    globals()['category{}_int'.format(j)].append(1)\n",
    "                elif globals()['df2_{}'.format(iterations)][columnname][i]=='Moderate':\n",
    "                    globals()['category{}_int'.format(j)].append(2)\n",
    "                else:\n",
    "                    globals()['category{}_int'.format(j)].append(3)\n",
    "\n",
    "        df_final=globals()['df2_{}'.format(iterations)]\n",
    "\n",
    "        for j in range(iterations):\n",
    "            columnname='category'+str(j)+'_int'\n",
    "            df_final[columnname]=globals()['category{}_int'.format(j)]\n",
    "\n",
    "        score_final=[]\n",
    "        category_final=[]\n",
    "        for i in range(len(df_final)):\n",
    "            score_temp=[]\n",
    "            category_temp=[]\n",
    "            for j in range(iterations):\n",
    "                columnname1='score'+str(j)\n",
    "                columname2='category'+str(j)+'_int'\n",
    "                score_temp.append(df_final[columnname1][i])\n",
    "                category_temp.append(df_final[columname2][i])\n",
    "\n",
    "            score_temptemp=np.nanmean(score_temp)\n",
    "            category_temptemp=np.nanmedian(category_temp)\n",
    "            score_final.append(score_temptemp)\n",
    "            category_final.append(category_temptemp)\n",
    "\n",
    "        df_final['score_final']=score_final\n",
    "        df_final['category_final']=category_final\n",
    "\n",
    "        cig_final=[]\n",
    "        for i in range(len(df_final)):\n",
    "            if df_final['smoking'][i]==2:\n",
    "                cig_final.append(1)\n",
    "            else:\n",
    "                cig_final.append(0)\n",
    "        df_final['Smoking']=cig_final\n",
    "\n",
    "        df_final['death_date']=pd.to_datetime(df_final['death_date'])\n",
    "        df_final['assess_date']=pd.to_datetime(df_final['assess_date'])\n",
    "        df_final['datediff']=df_final['death_date']-df_final['assess_date']\n",
    "\n",
    "        datediff_int=[]\n",
    "        for i in range(len(df_final)):\n",
    "            datediff_int.append(df_final['datediff'][i].days)\n",
    "\n",
    "        df_final['datediff_int']=datediff_int\n",
    "\n",
    "        datediff_int2=[]\n",
    "        event=[]\n",
    "        for i in range(len(df_final)):\n",
    "            if np.isnan(df_final['datediff_int'][i])==True:\n",
    "                datediff_int2.append(3650)\n",
    "                event.append(False)\n",
    "            else:\n",
    "                if df_final['datediff_int'][i]>3650:\n",
    "                    datediff_int2.append(3650)\n",
    "                    event.append(False)\n",
    "                else:\n",
    "                    datediff_int2.append(df_final['datediff_int'][i])\n",
    "                    event.append(True)\n",
    "        df_final['datediff_int2']=datediff_int2\n",
    "        df_final['event']=event\n",
    "\n",
    "        aa=list(df_final['datediff_int2'])\n",
    "        aa2=[x for x in aa if x < 3650]\n",
    "        aaa=[x for x in aa if x >=0]\n",
    "        aaaa=[x for x in aaa if x < 3650]\n",
    "        exclusion_event_before_assessment=len(aa2)-len(aaaa)\n",
    "        bb=exclusion_event_before_assessment\n",
    "\n",
    "        print('allcausemortality_within10years=',len(aa2)-bb,'/',upto-bb, \", exclusion_event_before_assessment=\",bb)\n",
    "\n",
    "        txt+= (  'allcausemortality_within10years=' + str(len(aa2)-bb) + ' / ' + str(upto-bb)+ \" , exclusion_event_before_assessment= \"+ str(bb) + '\\n'  )\n",
    "\n",
    "        algo=pd.read_csv('ukb_algorithmic_outcome.csv')\n",
    "        algo=algo[['eid','Min_Date']]\n",
    "        algo.columns=['eid','algo_date']\n",
    "        algo['algo_date']=pd.to_datetime(algo['algo_date'])\n",
    "\n",
    "        firstoccur=pd.read_csv('ukb_new_add_first_occur.csv')\n",
    "        firstoccur=firstoccur[['eid','Min_Date']]\n",
    "        firstoccur.columns=['eid','firstoccur_date']\n",
    "        firstoccur['firstoccur_date']=pd.to_datetime(firstoccur['firstoccur_date'])\n",
    "\n",
    "        df_final=pd.merge(df_final, algo, left_on='eid', right_on='eid', how='left')\n",
    "        df_final=pd.merge(df_final, firstoccur, left_on='eid', right_on='eid', how='left')\n",
    "\n",
    "        df_final['datediff_algo']=df_final['algo_date']-df_final['assess_date']\n",
    "        df_final['datediff_firstoccur']=df_final['firstoccur_date']-df_final['assess_date']\n",
    "\n",
    "        datediff_int=[]\n",
    "        for i in range(len(df_final)):\n",
    "            datediff_int.append(df_final['datediff_algo'][i].days)\n",
    "\n",
    "        df_final['datediff_algo_int']=datediff_int\n",
    "\n",
    "        datediff_int2=[]\n",
    "        event=[]\n",
    "        for i in range(len(df_final)):\n",
    "            if np.isnan(df_final['datediff_algo_int'][i])==True:\n",
    "                datediff_int2.append(3650)\n",
    "                event.append(False)\n",
    "            else:\n",
    "                if df_final['datediff_algo_int'][i]>3650:\n",
    "                    datediff_int2.append(3650)\n",
    "                    event.append(False)\n",
    "                else:\n",
    "                    datediff_int2.append(df_final['datediff_algo_int'][i])\n",
    "                    event.append(True)\n",
    "        df_final['datediff_algo_int2']=datediff_int2\n",
    "        df_final['algo_event']=event\n",
    "\n",
    "        aa=list(df_final['datediff_algo_int2'])\n",
    "        aa2=[x for x in aa if x < 3650]\n",
    "        aaa=[x for x in aa if x >=0]\n",
    "        aaaa=[x for x in aaa if x < 3650]\n",
    "        exclusion_event_before_assessment=len(aa2)-len(aaaa)\n",
    "        bb=exclusion_event_before_assessment\n",
    "        print('algoMACE_within10years=',len(aa2)-bb,'/',upto-bb, \", exclusion_event_before_assessment=\",bb)\n",
    "\n",
    "        txt+= (  'algoMACE_within10years=' + str(len(aa2)-bb) + ' / ' + str(upto-bb)+ \" , exclusion_event_before_assessment= \"+ str(bb) + '\\n'  )\n",
    "\n",
    "\n",
    "        datediff_int=[]\n",
    "        for i in range(len(df_final)):\n",
    "            datediff_int.append(df_final['datediff_firstoccur'][i].days)\n",
    "\n",
    "        df_final['datediff_firstoccur_int']=datediff_int\n",
    "\n",
    "        datediff_int2=[]\n",
    "        event=[]\n",
    "        for i in range(len(df_final)):\n",
    "            if np.isnan(df_final['datediff_firstoccur_int'][i])==True:\n",
    "                datediff_int2.append(3650)\n",
    "                event.append(False)\n",
    "            else:\n",
    "                if df_final['datediff_firstoccur_int'][i]>3650:\n",
    "                    datediff_int2.append(3650)\n",
    "                    event.append(False)\n",
    "                else:\n",
    "                    datediff_int2.append(df_final['datediff_firstoccur_int'][i])\n",
    "                    event.append(True)\n",
    "        df_final['datediff_firstoccur_int2']=datediff_int2\n",
    "        df_final['firstoccur_event']=event\n",
    "\n",
    "        aa=list(df_final['datediff_firstoccur_int2'])\n",
    "        aa2=[x for x in aa if x < 3650]\n",
    "        aaa=[x for x in aa if x >=0]\n",
    "        aaaa=[x for x in aaa if x < 3650]\n",
    "        exclusion_event_before_assessment=len(aa2)-len(aaaa)\n",
    "        bb=exclusion_event_before_assessment\n",
    "        print('firstoccurMACE_within10years=',len(aa2)-bb,'/',upto-bb, \", exclusion_event_before_assessment=\",bb)\n",
    "\n",
    "        txt+= (  'firstoccurMACE_within10years=' + str(len(aa2)-bb) + ' / ' + str(upto-bb)+ \" , exclusion_event_before_assessment= \"+ str(bb) + '\\n'  )\n",
    "\n",
    "\n",
    "        framingham_cat=[]\n",
    "        for i in range(len(df_final)):\n",
    "            if df_final['Framingham'][i]<=10:\n",
    "                framingham_cat.append(1)\n",
    "            elif df_final['Framingham'][i]<=20:\n",
    "                framingham_cat.append(2)\n",
    "            else:\n",
    "                framingham_cat.append(3)\n",
    "\n",
    "        df_final['framingham_cat']=framingham_cat\n",
    "\n",
    "        ACC_AHA_cat=[]\n",
    "        for i in range(len(df_final)):\n",
    "            if df_final['ACC/AHA'][i]<=7.5:\n",
    "                ACC_AHA_cat.append(1)\n",
    "            elif df_final['ACC/AHA'][i]<=20:\n",
    "                ACC_AHA_cat.append(2)\n",
    "            else:\n",
    "                ACC_AHA_cat.append(3)\n",
    "\n",
    "        df_final['ACC_AHA_cat']=ACC_AHA_cat\n",
    "\n",
    "        score1list=list(df_final['score_final'])\n",
    "        score2list=list(df_final['Framingham'])\n",
    "        score3list=list(df_final['ACC/AHA'])\n",
    "\n",
    "        score1list.sort()\n",
    "        score2list.sort()\n",
    "        score3list.sort()\n",
    "\n",
    "        score1_newcat=[]\n",
    "        score2_newcat=[]\n",
    "        score3_newcat=[]\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(len(df_final)):\n",
    "            if df_final['score_final'][i]<score1list[round(upto*0.6)]:\n",
    "                score1_newcat.append(1)\n",
    "            elif df_final['score_final'][i]<score1list[round(upto*0.9)]:\n",
    "                score1_newcat.append(2)\n",
    "            else:\n",
    "                score1_newcat.append(3)\n",
    "\n",
    "            if df_final['Framingham'][i]<score2list[round(upto*0.6)]:\n",
    "                score2_newcat.append(1)\n",
    "            elif df_final['Framingham'][i]<score2list[round(upto*0.9)]:\n",
    "                score2_newcat.append(2)\n",
    "            else:\n",
    "                score2_newcat.append(3)\n",
    "\n",
    "            if df_final['ACC/AHA'][i]<score3list[round(upto*0.6)]:\n",
    "                score3_newcat.append(1)\n",
    "            elif df_final['ACC/AHA'][i]<score3list[round(upto*0.9)]:\n",
    "                score3_newcat.append(2)\n",
    "            else:\n",
    "                score3_newcat.append(3)\n",
    "\n",
    "        df_final['score1_newcat']=score1_newcat\n",
    "        df_final['score2_newcat']=score2_newcat\n",
    "        df_final['score3_newcat']=score3_newcat\n",
    "\n",
    "        cutofftxt+= 'allcausemortality, ChatGPT_score, 0.6, 0.9\\n'\n",
    "        cutofftxt+= (str(round(score1list[round(upto*0.6)],1)) + '\\n')\n",
    "        cutofftxt+= (str(round(score1list[round(upto*0.9)],1)) + '\\n')\n",
    "        cutofftxt+= 'allcausemortality, Framingham, 0.6, 0.9\\n'\n",
    "        cutofftxt+= (str(round(score2list[round(upto*0.6)],1)) + '\\n')\n",
    "        cutofftxt+= (str(round(score2list[round(upto*0.9)],1)) + '\\n')\n",
    "        cutofftxt+= 'allcausemortality, ACC/AHA, 0.6, 0.9\\n'\n",
    "        cutofftxt+= (str(round(score3list[round(upto*0.6)],1)) + '\\n')\n",
    "        cutofftxt+= (str(round(score3list[round(upto*0.9)],1)) + '\\n')\n",
    "\n",
    "\n",
    "        df_final_temp=df_final[df_final['datediff_algo_int2']<=3650]\n",
    "        df_final_temp=df_final_temp[df_final_temp['datediff_algo_int2']>=0]\n",
    "        df_final_temp.reset_index(inplace=True,drop=True)\n",
    "        df_final_temp.to_csv('20230818_50000_5iter2_finaldf_algo.csv',index=False)\n",
    "        score1list=list(df_final_temp['score_final'])\n",
    "        score2list=list(df_final_temp['Framingham'])\n",
    "        score3list=list(df_final_temp['ACC/AHA'])\n",
    "\n",
    "        score1list.sort()\n",
    "        score2list.sort()\n",
    "        score3list.sort()\n",
    "\n",
    "        score1_newcat=[]\n",
    "        score2_newcat=[]\n",
    "        score3_newcat=[]\n",
    "\n",
    "        for i in range(len(df_final_temp)):\n",
    "            if df_final_temp['score_final'][i]<score1list[round(upto*0.6)]:\n",
    "                score1_newcat.append(1)\n",
    "            elif df_final_temp['score_final'][i]<score1list[round(upto*0.9)]:\n",
    "                score1_newcat.append(2)\n",
    "            else:\n",
    "                score1_newcat.append(3)\n",
    "\n",
    "            if df_final_temp['Framingham'][i]<score2list[round(upto*0.6)]:\n",
    "                score2_newcat.append(1)\n",
    "            elif df_final_temp['Framingham'][i]<score2list[round(upto*0.9)]:\n",
    "                score2_newcat.append(2)\n",
    "            else:\n",
    "                score2_newcat.append(3)\n",
    "\n",
    "            if df_final_temp['ACC/AHA'][i]<score3list[round(upto*0.6)]:\n",
    "                score3_newcat.append(1)\n",
    "            elif df_final_temp['ACC/AHA'][i]<score3list[round(upto*0.9)]:\n",
    "                score3_newcat.append(2)\n",
    "            else:\n",
    "                score3_newcat.append(3)\n",
    "\n",
    "        df_final_temp['score1_newcat_algoMACE']=score1_newcat\n",
    "        df_final_temp['score2_newcat_algoMACE']=score2_newcat\n",
    "        df_final_temp['score3_newcat_algoMACE']=score3_newcat\n",
    "        df_final_temp=df_final_temp[['eid','score1_newcat_algoMACE','score2_newcat_algoMACE','score3_newcat_algoMACE']]\n",
    "        df_final=pd.merge(df_final, df_final_temp, left_on='eid', right_on='eid', how='left')\n",
    "\n",
    "\n",
    "        cutofftxt+= 'algoMACE, ChatGPT_score, 0.6, 0.9\\n'\n",
    "        cutofftxt+= (str(round(score1list[round(upto*0.6)],1)) + '\\n')\n",
    "        cutofftxt+= (str(round(score1list[round(upto*0.9)],1)) + '\\n')\n",
    "        cutofftxt+= 'algoMACE, Framingham, 0.6, 0.9\\n'\n",
    "        cutofftxt+= (str(round(score2list[round(upto*0.6)],1)) + '\\n')\n",
    "        cutofftxt+= (str(round(score2list[round(upto*0.9)],1)) + '\\n')\n",
    "        cutofftxt+= 'algoMACE, ACC/AHA, 0.6, 0.9\\n'\n",
    "        cutofftxt+= (str(round(score3list[round(upto*0.6)],1)) + '\\n')\n",
    "        cutofftxt+= (str(round(score3list[round(upto*0.9)],1)) + '\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        df_final_temp=df_final[df_final['datediff_firstoccur_int2']<=3650]\n",
    "        df_final_temp=df_final_temp[df_final_temp['datediff_firstoccur_int2']>=0]\n",
    "        df_final_temp.reset_index(inplace=True,drop=True)\n",
    "        df_final_temp.to_csv('20230818_50000_5iter2_finaldf_firstoccur.csv',index=False)\n",
    "        score1list=list(df_final_temp['score_final'])\n",
    "        score2list=list(df_final_temp['Framingham'])\n",
    "        score3list=list(df_final_temp['ACC/AHA'])\n",
    "\n",
    "        score1list.sort()\n",
    "        score2list.sort()\n",
    "        score3list.sort()\n",
    "\n",
    "        score1_newcat=[]\n",
    "        score2_newcat=[]\n",
    "        score3_newcat=[]\n",
    "\n",
    "        for i in range(len(df_final_temp)):\n",
    "            if df_final_temp['score_final'][i]<score1list[round(upto*0.6)]:\n",
    "                score1_newcat.append(1)\n",
    "            elif df_final_temp['score_final'][i]<score1list[round(upto*0.9)]:\n",
    "                score1_newcat.append(2)\n",
    "            else:\n",
    "                score1_newcat.append(3)\n",
    "\n",
    "            if df_final_temp['Framingham'][i]<score2list[round(upto*0.6)]:\n",
    "                score2_newcat.append(1)\n",
    "            elif df_final_temp['Framingham'][i]<score2list[round(upto*0.9)]:\n",
    "                score2_newcat.append(2)\n",
    "            else:\n",
    "                score2_newcat.append(3)\n",
    "\n",
    "            if df_final_temp['ACC/AHA'][i]<score3list[round(upto*0.6)]:\n",
    "                score3_newcat.append(1)\n",
    "            elif df_final_temp['ACC/AHA'][i]<score3list[round(upto*0.9)]:\n",
    "                score3_newcat.append(2)\n",
    "            else:\n",
    "                score3_newcat.append(3)\n",
    "\n",
    "        df_final_temp['score1_newcat_firstoccurMACE']=score1_newcat\n",
    "        df_final_temp['score2_newcat_firstoccurMACE']=score2_newcat\n",
    "        df_final_temp['score3_newcat_firstoccurMACE']=score3_newcat\n",
    "        df_final_temp=df_final_temp[['eid','score1_newcat_firstoccurMACE','score2_newcat_firstoccurMACE','score3_newcat_firstoccurMACE']]\n",
    "        df_final=pd.merge(df_final, df_final_temp, left_on='eid', right_on='eid', how='left')\n",
    "\n",
    "        cutofftxt+= 'firstoccurMACE, ChatGPT_score, 0.6, 0.9\\n'\n",
    "        cutofftxt+= (str(round(score1list[round(upto*0.6)],1)) + '\\n')\n",
    "        cutofftxt+= (str(round(score1list[round(upto*0.9)],1)) + '\\n')\n",
    "        cutofftxt+= 'firstoccurMACE, Framingham, 0.6, 0.9\\n'\n",
    "        cutofftxt+= (str(round(score2list[round(upto*0.6)],1)) + '\\n')\n",
    "        cutofftxt+= (str(round(score2list[round(upto*0.9)],1)) + '\\n')\n",
    "        cutofftxt+= 'firstoccurMACE, ACC/AHA, 0.6, 0.9\\n'\n",
    "        cutofftxt+= (str(round(score3list[round(upto*0.6)],1)) + '\\n')\n",
    "        cutofftxt+= (str(round(score3list[round(upto*0.9)],1)) + '\\n')\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            os.mkdir(newtablename)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        file = open(newtablename+\"/samplenumber.txt\", \"w\") \n",
    "        file.write(txt)\n",
    "        file.close()\n",
    "\n",
    "        file = open(newtablename+\"/60percent90percent_cutoffs.txt\", \"w\") \n",
    "        file.write(cutofftxt)\n",
    "        file.close()\n",
    "\n",
    "        #df_final=df_final.dropna(subset='score0',axis=0)\n",
    "        #df_final.reset_index(inplace=True,drop=True)\n",
    "\n",
    "\n",
    "        ######## 설정변수 ##########\n",
    "        ylim1_survival_allcausemortality=0.86\n",
    "        ylim2_survival_allcausemortality=1.01\n",
    "        ylim1_survival_algoMACE=0.90\n",
    "        ylim2_survival_algoMACE=1.01\n",
    "        ylim1_survival_firstoccurMACE=0.82\n",
    "        ylim2_survival_firstoccurMACE=1.01\n",
    "\n",
    "\n",
    "        ############################\n",
    "        txt=''\n",
    "        txt_men_40=''\n",
    "        txt_women_40=''\n",
    "        txt_men_50=''\n",
    "        txt_women_50=''\n",
    "        txt_men_60=''\n",
    "        txt_women_60=''\n",
    "        txt_men_allages=''\n",
    "        txt_women_allages=''\n",
    "        txt_bothsex_40=''\n",
    "        txt_bothsex_50=''\n",
    "        txt_bothsex_60=''\n",
    "\n",
    "        catnamedict={}\n",
    "        catnamedict['ChatGPT (Original)']='category_final'\n",
    "        catnamedict['ChatGPT (6:3:1)']='score1_newcat'\n",
    "        catnamedict['Framingham (Original)']='framingham_cat'\n",
    "        catnamedict['Framingham (6:3:1)']='score2_newcat'\n",
    "        catnamedict['ACC/AHA ASCVD (Original)']='ACC_AHA_cat'\n",
    "        catnamedict['ACC/AHA ASCVD (6:3:1)']='score3_newcat'\n",
    "\n",
    "        scorenamedict={}\n",
    "        scorenamedict['ChatGPT (Original)']='score_final'\n",
    "        #scorenamedict['ChatGPT (Original)']='score0'\n",
    "        scorenamedict['ChatGPT (6:3:1)']='score_final'\n",
    "        scorenamedict['Framingham (Original)']='Framingham'\n",
    "        scorenamedict['Framingham (6:3:1)']='Framingham'\n",
    "        scorenamedict['ACC/AHA ASCVD (Original)']='ACC/AHA'\n",
    "        scorenamedict['ACC/AHA ASCVD (6:3:1)']='ACC/AHA'\n",
    "\n",
    "        outcome_event_dict={}\n",
    "        outcome_event_dict['allcausemortality']='event'\n",
    "        outcome_event_dict['algoMACE']='algo_event'\n",
    "        outcome_event_dict['firstoccurMACE']='firstoccur_event'\n",
    "\n",
    "        outcome_datediff_dict={}\n",
    "        outcome_datediff_dict['allcausemortality']='datediff_int2'\n",
    "        outcome_datediff_dict['algoMACE']='datediff_algo_int2'\n",
    "        outcome_datediff_dict['firstoccurMACE']='datediff_firstoccur_int2'\n",
    "\n",
    "        ylim1_dict={}\n",
    "        ylim1_dict['allcausemortality']=ylim1_survival_allcausemortality\n",
    "        ylim1_dict['algoMACE']=ylim1_survival_algoMACE\n",
    "        ylim1_dict['firstoccurMACE']=ylim1_survival_firstoccurMACE\n",
    "\n",
    "        ylim2_dict={}\n",
    "        ylim2_dict['allcausemortality']=ylim2_survival_allcausemortality\n",
    "        ylim2_dict['algoMACE']=ylim2_survival_algoMACE\n",
    "        ylim2_dict['firstoccurMACE']=ylim2_survival_firstoccurMACE\n",
    "\n",
    "        def survivalgraph(catname1,catname2,outcome,ylim1,ylim2):\n",
    "            global txt\n",
    "            global txt_men_40\n",
    "            global txt_men_50\n",
    "            global txt_men_60\n",
    "            global txt_women_40\n",
    "            global txt_women_50\n",
    "            global txt_women_60\n",
    "            global txt_bothsex_40\n",
    "            global txt_bothsex_50\n",
    "            global txt_bothsex_60\n",
    "            global txt_men_allages\n",
    "            global txt_women_allages\n",
    "            datediff_temp=outcome_datediff_dict[outcome]\n",
    "            event_temp=outcome_event_dict[outcome]\n",
    "            score_temp=scorenamedict[catname1]\n",
    "\n",
    "            df_final_temp=df_final[df_final[datediff_temp]<=3650][['age','sex',catname2,datediff_temp,event_temp,score_temp]]\n",
    "            df_final_temp=df_final_temp[df_final_temp[datediff_temp]>=0]\n",
    "\n",
    "            #df_final_temp2=df_final_temp[[event_temp,score_temp]]\n",
    "            #print(len(df_final_temp2))\n",
    "            #df_final_temp2=df_final_temp2.dropna()\n",
    "            #fpr,tpr,thres=roc_curve(df_final_temp2[event_temp],df_final_temp2[score_temp])\n",
    "            #roc_auc = round(auc(fpr, tpr),3)\n",
    "            #print(len(df_final_temp2),np.sum(df_final_temp2[event_temp]),roc_auc)\n",
    "\n",
    "            fpr,tpr,thres=roc_curve(df_final_temp[event_temp],df_final_temp[score_temp])\n",
    "            roc_auc = round(auc(fpr, tpr),3)\n",
    "\n",
    "            df_final_temp_men_40=df_final_temp[df_final_temp['age']>=40]\n",
    "            df_final_temp_men_40=df_final_temp_men_40[df_final_temp_men_40['age']<50]\n",
    "            df_final_temp_men_40=df_final_temp_men_40[df_final_temp_men_40['sex']==1]\n",
    "            df_final_temp_men_40.reset_index(inplace=True,drop=True)\n",
    "\n",
    "            df_final_temp_men_50=df_final_temp[df_final_temp['age']>=50]\n",
    "            df_final_temp_men_50=df_final_temp_men_50[df_final_temp_men_50['age']<60]\n",
    "            df_final_temp_men_50=df_final_temp_men_50[df_final_temp_men_50['sex']==1]\n",
    "            df_final_temp_men_50.reset_index(inplace=True,drop=True)\n",
    "\n",
    "            df_final_temp_men_60=df_final_temp[df_final_temp['age']>=60]\n",
    "            df_final_temp_men_60=df_final_temp_men_60[df_final_temp_men_60['age']<71]\n",
    "            df_final_temp_men_60=df_final_temp_men_60[df_final_temp_men_60['sex']==1]\n",
    "            df_final_temp_men_60.reset_index(inplace=True,drop=True)\n",
    "\n",
    "            df_final_temp_women_40=df_final_temp[df_final_temp['age']>=40]\n",
    "            df_final_temp_women_40=df_final_temp_women_40[df_final_temp_women_40['age']<50]\n",
    "            df_final_temp_women_40=df_final_temp_women_40[df_final_temp_women_40['sex']==0]\n",
    "            df_final_temp_women_40.reset_index(inplace=True,drop=True)\n",
    "\n",
    "            df_final_temp_women_50=df_final_temp[df_final_temp['age']>=50]\n",
    "            df_final_temp_women_50=df_final_temp_women_50[df_final_temp_women_50['age']<60]\n",
    "            df_final_temp_women_50=df_final_temp_women_50[df_final_temp_women_50['sex']==0]\n",
    "            df_final_temp_women_50.reset_index(inplace=True,drop=True)\n",
    "\n",
    "            df_final_temp_women_60=df_final_temp[df_final_temp['age']>=60]\n",
    "            df_final_temp_women_60=df_final_temp_women_60[df_final_temp_women_60['age']<71]\n",
    "            df_final_temp_women_60=df_final_temp_women_60[df_final_temp_women_60['sex']==0]\n",
    "            df_final_temp_women_60.reset_index(inplace=True,drop=True)\n",
    "\n",
    "            df_final_temp_bothsex_40=df_final_temp[df_final_temp['age']>=40]\n",
    "            df_final_temp_bothsex_40=df_final_temp_bothsex_40[df_final_temp_bothsex_40['age']<50]\n",
    "            df_final_temp_bothsex_40.reset_index(inplace=True,drop=True)\n",
    "\n",
    "            df_final_temp_bothsex_50=df_final_temp[df_final_temp['age']>=50]\n",
    "            df_final_temp_bothsex_50=df_final_temp_bothsex_50[df_final_temp_bothsex_50['age']<60]\n",
    "            df_final_temp_bothsex_50.reset_index(inplace=True,drop=True)\n",
    "\n",
    "            df_final_temp_bothsex_60=df_final_temp[df_final_temp['age']>=60]\n",
    "            df_final_temp_bothsex_60=df_final_temp_bothsex_60[df_final_temp_bothsex_60['age']<71]\n",
    "            df_final_temp_bothsex_60.reset_index(inplace=True,drop=True)\n",
    "\n",
    "            df_final_temp_men_allages=df_final_temp[df_final_temp['sex']==1]\n",
    "            df_final_temp_men_allages.reset_index(inplace=True,drop=True)\n",
    "\n",
    "            df_final_temp_women_allages=df_final_temp[df_final_temp['sex']==0]\n",
    "            df_final_temp_women_allages.reset_index(inplace=True,drop=True)\n",
    "\n",
    "            fpr,tpr,thres=roc_curve(df_final_temp_men_40[event_temp],df_final_temp_men_40[score_temp])\n",
    "            roc_auc_men_40 = round(auc(fpr, tpr),3)\n",
    "\n",
    "            fpr,tpr,thres=roc_curve(df_final_temp_men_50[event_temp],df_final_temp_men_50[score_temp])\n",
    "            roc_auc_men_50 = round(auc(fpr, tpr),3)\n",
    "\n",
    "            fpr,tpr,thres=roc_curve(df_final_temp_men_60[event_temp],df_final_temp_men_60[score_temp])\n",
    "            roc_auc_men_60 = round(auc(fpr, tpr),3)\n",
    "\n",
    "            fpr,tpr,thres=roc_curve(df_final_temp_women_40[event_temp],df_final_temp_women_40[score_temp])\n",
    "            roc_auc_women_40 = round(auc(fpr, tpr),3)\n",
    "\n",
    "            fpr,tpr,thres=roc_curve(df_final_temp_women_50[event_temp],df_final_temp_women_50[score_temp])\n",
    "            roc_auc_women_50 = round(auc(fpr, tpr),3)\n",
    "\n",
    "            fpr,tpr,thres=roc_curve(df_final_temp_women_60[event_temp],df_final_temp_women_60[score_temp])\n",
    "            roc_auc_women_60 = round(auc(fpr, tpr),3)\n",
    "\n",
    "            fpr,tpr,thres=roc_curve(df_final_temp_bothsex_40[event_temp],df_final_temp_bothsex_40[score_temp])\n",
    "            roc_auc_bothsex_40 = round(auc(fpr, tpr),3)\n",
    "\n",
    "            fpr,tpr,thres=roc_curve(df_final_temp_bothsex_50[event_temp],df_final_temp_bothsex_50[score_temp])\n",
    "            roc_auc_bothsex_50 = round(auc(fpr, tpr),3)\n",
    "\n",
    "            fpr,tpr,thres=roc_curve(df_final_temp_bothsex_60[event_temp],df_final_temp_bothsex_60[score_temp])\n",
    "            roc_auc_bothsex_60 = round(auc(fpr, tpr),3)\n",
    "\n",
    "            fpr,tpr,thres=roc_curve(df_final_temp_men_allages[event_temp],df_final_temp_men_allages[score_temp])\n",
    "            roc_auc_men_allages = round(auc(fpr, tpr),3)\n",
    "\n",
    "            fpr,tpr,thres=roc_curve(df_final_temp_women_allages[event_temp],df_final_temp_women_allages[score_temp])\n",
    "            roc_auc_women_allages = round(auc(fpr, tpr),3)\n",
    "\n",
    "\n",
    "\n",
    "            cat1 = df_final_temp[df_final_temp[catname2] == 1]\n",
    "            cat2 = df_final_temp[df_final_temp[catname2] == 2]\n",
    "            cat3 = df_final_temp[df_final_temp[catname2] == 3]\n",
    "            print(outcome,catname2, len(cat1),len(cat2),len(cat3))\n",
    "\n",
    "            kmf = KaplanMeierFitter()\n",
    "            kmf.fit(cat1[datediff_temp], cat1[event_temp], label='Low')\n",
    "            ax_kmf = kmf.plot(loc=slice(0.,3650.))\n",
    "            kmf.fit(cat2[datediff_temp], cat2[event_temp], label='Moderate')\n",
    "            ax_kmf = kmf.plot(ax = ax_kmf,loc=slice(0.,3650.))\n",
    "            kmf.fit(cat3[datediff_temp], cat3[event_temp], label='High')\n",
    "            ax_kmf = kmf.plot(ax = ax_kmf,loc=slice(0.,3650.))\n",
    "\n",
    "            ax_kmf.set_ylim([ylim1, ylim2])\n",
    "            ax_kmf.set_yticks(np.arange(ylim1, ylim2, step=0.02))\n",
    "            ax_kmf.set_xlabel('Time (days)')\n",
    "            ax_kmf.set_ylabel('Survival Rate')\n",
    "            ['ChatGPT (Original)','ChatGPT (6:3:1)','Framingham (Original)','Framingham (6:3:1)' ,'ACC/AHA ASCVD (Original)','ACC/AHA ASCVD (6:3:1)']\n",
    "            if catname1=='ChatGPT (Original)':\n",
    "                ax_kmf.set_title('GPT-4')\n",
    "            elif catname1=='Framingham (Original)':\n",
    "                ax_kmf.set_title('Framingham')\n",
    "            elif catname1=='ACC/AHA ASCVD (Original)':\n",
    "                ax_kmf.set_title('ACC/AHA')\n",
    "            else:\n",
    "                ax_kmf.set_title(catname1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            try:\n",
    "                os.mkdir(newtablename)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                os.mkdir(newtablename+'/survival')\n",
    "            except:\n",
    "                pass\n",
    "            catname1_temp=catname1.replace(' ','_')\n",
    "            catname1_temp=catname1_temp.replace('(','_')\n",
    "            catname1_temp=catname1_temp.replace(')','')\n",
    "            catname1_temp=catname1_temp.replace(':','')\n",
    "            catname1_temp=catname1_temp.replace('/','')\n",
    "            ax_kmf.get_figure().savefig(newtablename+\"/survival/\"+outcome+'_' +catname1_temp+   \".png\",transparent=True)\n",
    "            plt.close('all')\n",
    "\n",
    "            if catname1=='ChatGPT (Original)':\n",
    "                txt+= ('ChatGPT' + ' AUROC = ' + str(roc_auc) +'\\n' )\n",
    "                txt_men_40+= ('ChatGPT' + ' AUROC = ' + str(roc_auc_men_40) +'\\n' )\n",
    "                txt_men_50+= ('ChatGPT' + ' AUROC = ' + str(roc_auc_men_50) +'\\n' )\n",
    "                txt_men_60+= ('ChatGPT' + ' AUROC = ' + str(roc_auc_men_60) +'\\n' )\n",
    "                txt_women_40+= ('ChatGPT' + ' AUROC = ' + str(roc_auc_women_40) +'\\n' )\n",
    "                txt_women_50+= ('ChatGPT' + ' AUROC = ' + str(roc_auc_women_50) +'\\n' )\n",
    "                txt_women_60+= ('ChatGPT' + ' AUROC = ' + str(roc_auc_women_60) +'\\n' )\n",
    "                txt_bothsex_40+= ('ChatGPT' + ' AUROC = ' + str(roc_auc_bothsex_40) +'\\n' )\n",
    "                txt_bothsex_50+= ('ChatGPT' + ' AUROC = ' + str(roc_auc_bothsex_50) +'\\n' )\n",
    "                txt_bothsex_60+= ('ChatGPT' + ' AUROC = ' + str(roc_auc_bothsex_60) +'\\n' )\n",
    "                txt_men_allages+= ('ChatGPT' + ' AUROC = ' + str(roc_auc_men_allages) +'\\n' )\n",
    "                txt_women_allages+= ('ChatGPT' + ' AUROC = ' + str(roc_auc_women_allages) +'\\n' )\n",
    "            elif catname1=='Framingham (Original)':\n",
    "                txt+= ('Framingham' + ' AUROC = ' + str(roc_auc) +'\\n' )\n",
    "                txt_men_40+= ('Framingham' + ' AUROC = ' + str(roc_auc_men_40) +'\\n' )\n",
    "                txt_men_50+= ('Framingham' + ' AUROC = ' + str(roc_auc_men_50) +'\\n' )\n",
    "                txt_men_60+= ('Framingham' + ' AUROC = ' + str(roc_auc_men_60) +'\\n' )\n",
    "                txt_women_40+= ('Framingham' + ' AUROC = ' + str(roc_auc_women_40) +'\\n' )\n",
    "                txt_women_50+= ('Framingham' + ' AUROC = ' + str(roc_auc_women_50) +'\\n' )\n",
    "                txt_women_60+= ('Framingham' + ' AUROC = ' + str(roc_auc_women_60) +'\\n' )\n",
    "                txt_bothsex_40+= ('Framingham' + ' AUROC = ' + str(roc_auc_bothsex_40) +'\\n' )\n",
    "                txt_bothsex_50+= ('Framingham' + ' AUROC = ' + str(roc_auc_bothsex_50) +'\\n' )\n",
    "                txt_bothsex_60+= ('Framingham' + ' AUROC = ' + str(roc_auc_bothsex_60) +'\\n' )\n",
    "                txt_men_allages+= ('Framingham' + ' AUROC = ' + str(roc_auc_men_allages) +'\\n' )\n",
    "                txt_women_allages+= ('Framingham' + ' AUROC = ' + str(roc_auc_women_allages) +'\\n' )\n",
    "            elif catname1=='ACC/AHA ASCVD (Original)':\n",
    "                txt+= ('ACC/AHA' + ' AUROC = ' + str(roc_auc) +'\\n' )\n",
    "                txt_men_40+= ('ACC/AHA' + ' AUROC = ' + str(roc_auc_men_40) +'\\n' )\n",
    "                txt_men_50+= ('ACC/AHA' + ' AUROC = ' + str(roc_auc_men_50) +'\\n' )\n",
    "                txt_men_60+= ('ACC/AHA' + ' AUROC = ' + str(roc_auc_men_60) +'\\n' )\n",
    "                txt_women_40+= ('ACC/AHA' + ' AUROC = ' + str(roc_auc_women_40) +'\\n' )\n",
    "                txt_women_50+= ('ACC/AHA' + ' AUROC = ' + str(roc_auc_women_50) +'\\n' )\n",
    "                txt_women_60+= ('ACC/AHA' + ' AUROC = ' + str(roc_auc_women_60) +'\\n' )\n",
    "                txt_bothsex_40+= ('ACC/AHA' + ' AUROC = ' + str(roc_auc_bothsex_40) +'\\n' )\n",
    "                txt_bothsex_50+= ('ACC/AHA' + ' AUROC = ' + str(roc_auc_bothsex_50) +'\\n' )\n",
    "                txt_bothsex_60+= ('ACC/AHA' + ' AUROC = ' + str(roc_auc_bothsex_60) +'\\n' )\n",
    "                txt_men_allages+= ('ACC/AHA' + ' AUROC = ' + str(roc_auc_men_allages) +'\\n' )\n",
    "                txt_women_allages+= ('ACC/AHA' + ' AUROC = ' + str(roc_auc_women_allages) +'\\n' )\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for outcome in ['allcausemortality','algoMACE','firstoccurMACE']:\n",
    "            count=0\n",
    "            for catname1 in ['ChatGPT (Original)','ChatGPT (6:3:1)','Framingham (Original)','Framingham (6:3:1)' ,'ACC/AHA ASCVD (Original)','ACC/AHA ASCVD (6:3:1)']:\n",
    "                if count==0:\n",
    "                    txt+='===== ' +outcome+' ====='+'\\n'\n",
    "                    txt_men_40+='===== ' +outcome+' ====='+'\\n'\n",
    "                    txt_men_50+='===== ' +outcome+' ====='+'\\n'\n",
    "                    txt_men_60+='===== ' +outcome+' ====='+'\\n'\n",
    "                    txt_women_40+='===== ' +outcome+' ====='+'\\n'\n",
    "                    txt_women_50+='===== ' +outcome+' ====='+'\\n'\n",
    "                    txt_women_60+='===== ' +outcome+' ====='+'\\n'\n",
    "                    txt_bothsex_40+='===== ' +outcome+' ====='+'\\n'\n",
    "                    txt_bothsex_50+='===== ' +outcome+' ====='+'\\n'\n",
    "                    txt_bothsex_60+='===== ' +outcome+' ====='+'\\n'\n",
    "                    txt_men_allages+='===== ' +outcome+' ====='+'\\n'\n",
    "                    txt_women_allages+='===== ' +outcome+' ====='+'\\n'\n",
    "                    count+=1\n",
    "\n",
    "                ylim1_survival=ylim1_dict[outcome]\n",
    "                ylim2_survival=ylim2_dict[outcome]\n",
    "                catname2=catnamedict[catname1]\n",
    "                survivalgraph(catname1,catname2,outcome,ylim1_survival,ylim2_survival)\n",
    "\n",
    "\n",
    "        file = open(newtablename+\"/AUROC.txt\", \"w\") \n",
    "        file.write(txt)\n",
    "        file.close()\n",
    "\n",
    "        file = open(newtablename+\"/AUROC_men_40.txt\", \"w\") \n",
    "        file.write(txt_men_40)\n",
    "        file.close()\n",
    "\n",
    "        file = open(newtablename+\"/AUROC_men_50.txt\", \"w\") \n",
    "        file.write(txt_men_50)\n",
    "        file.close()\n",
    "\n",
    "        file = open(newtablename+\"/AUROC_men_60.txt\", \"w\") \n",
    "        file.write(txt_men_60)\n",
    "        file.close()\n",
    "\n",
    "        file = open(newtablename+\"/AUROC_women_40.txt\", \"w\") \n",
    "        file.write(txt_women_40)\n",
    "        file.close()\n",
    "\n",
    "        file = open(newtablename+\"/AUROC_women_50.txt\", \"w\") \n",
    "        file.write(txt_women_50)\n",
    "        file.close()\n",
    "\n",
    "        file = open(newtablename+\"/AUROC_women_60.txt\", \"w\") \n",
    "        file.write(txt_women_60)\n",
    "        file.close()\n",
    "\n",
    "        file = open(newtablename+\"/AUROC_bothsex_40.txt\", \"w\") \n",
    "        file.write(txt_bothsex_40)\n",
    "        file.close()\n",
    "\n",
    "        file = open(newtablename+\"/AUROC_bothsex_50.txt\", \"w\") \n",
    "        file.write(txt_bothsex_50)\n",
    "        file.close()\n",
    "\n",
    "        file = open(newtablename+\"/AUROC_bothsex_60.txt\", \"w\") \n",
    "        file.write(txt_bothsex_60)\n",
    "        file.close()\n",
    "\n",
    "        file = open(newtablename+\"/AUROC_men_allages.txt\", \"w\") \n",
    "        file.write(txt_men_allages)\n",
    "        file.close()\n",
    "\n",
    "        file = open(newtablename+\"/AUROC_women_allages.txt\", \"w\") \n",
    "        file.write(txt_women_allages)\n",
    "        file.close()\n",
    "\n",
    "        ######## 설정변수 ##########\n",
    "        lim=80\n",
    "\n",
    "\n",
    "        ############################\n",
    "\n",
    "\n",
    "        txt=''\n",
    "\n",
    "        def scatter_plot(xxx,yyy,lim):\n",
    "            global txt\n",
    "            plt.figure(figsize=(10,10))\n",
    "            if xxx=='ChatGPT':\n",
    "                xxxx='GPT-4'\n",
    "            else:\n",
    "                xxxx=xxx\n",
    "            if yyy=='ACC/AHA':\n",
    "                yyyy='ACC/AHA'\n",
    "            else:\n",
    "                yyyy=yyy\n",
    "\n",
    "\n",
    "\n",
    "            plt.title(xxxx+ ' VS '+ yyyy , fontsize=20)\n",
    "\n",
    "\n",
    "\n",
    "            if xxx=='ChatGPT':\n",
    "                plt.xlabel('GPT-4', fontsize=14)\n",
    "            else:\n",
    "                plt.xlabel(xxx, fontsize=14)\n",
    "            if yyy=='ACC/AHA':\n",
    "                plt.ylabel('ACC/AHA', fontsize=14)\n",
    "            else:\n",
    "                plt.ylabel(yyy, fontsize=14)\n",
    "\n",
    "            plt.xlim([-5, lim])\n",
    "            plt.ylim([-5, lim])\n",
    "            plt.yticks(np.arange(0, lim+10, step=10))\n",
    "            plt.xticks(np.arange(0, lim+10, step=10))\n",
    "            if xxx=='ChatGPT':\n",
    "                xxx_column='score_final'\n",
    "            elif xxx=='Framingham':\n",
    "                xxx_column='Framingham'\n",
    "            elif xxx=='ACC/AHA':\n",
    "                xxx_column='ACC/AHA'\n",
    "            else:\n",
    "                print('error')\n",
    "\n",
    "            if yyy=='ChatGPT':\n",
    "                yyy_column='score_final'\n",
    "            elif yyy=='Framingham':\n",
    "                yyy_column='Framingham'\n",
    "            elif yyy=='ACC/AHA':\n",
    "                yyy_column='ACC/AHA'\n",
    "            else:\n",
    "                print('error')    \n",
    "\n",
    "            try:\n",
    "                os.mkdir(newtablename)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                os.mkdir(newtablename+'/scatter')\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            xxx=xxx.replace('/','_')\n",
    "            yyy=yyy.replace('/','_')\n",
    "\n",
    "            plt.scatter(df_final[xxx_column],df_final[yyy_column],s=0.07, alpha=0.6)\n",
    "            plt.savefig(newtablename+\"/scatter/\"+xxx+'_'+yyy+\".png\",transparent=True)\n",
    "            plt.close('all')\n",
    "\n",
    "            pearr=round(pearsonr(df_final[xxx_column],df_final[yyy_column]).statistic,3)\n",
    "            pearp=round(pearsonr(df_final[xxx_column],df_final[yyy_column]).pvalue,3)\n",
    "\n",
    "            txt+='==========================\\n'\n",
    "            txt+=('--- '+xxx+ ' VS '+ yyy + ' ---'+'\\n')\n",
    "            txt+=('pearson r = ' + str(pearr)+', pearson pvalue = '+str(pearp)   + '\\n')\n",
    "            txt+=(   xxx +'_mean = '+ str(round(np.mean(df_final[xxx_column]),3))   + '\\n')\n",
    "            txt+=(   yyy +'_mean = '+ str(round(np.mean(df_final[yyy_column]),3))   + '\\n')\n",
    "            txt+=(   xxx +'_shapiro_pvalue = '+ str(round(shapiro(df_final[xxx_column]).pvalue,3))   + '\\n')\n",
    "            txt+=(   yyy +'_shapiro_pvalue = '+ str(round(shapiro(df_final[yyy_column]).pvalue,3))   + '\\n')\n",
    "            txt+=(   'mannwhitneyu_pvalue = '+ str(round(mwu(df_final[xxx_column],df_final[yyy_column]).pvalue,3))   + '\\n')\n",
    "\n",
    "\n",
    "\n",
    "        for xxx,yyy in [['ChatGPT','Framingham'],['ChatGPT','ACC/AHA'],['Framingham','ACC/AHA']]:\n",
    "            scatter_plot(xxx,yyy,lim)\n",
    "\n",
    "        txt+='=========================='\n",
    "\n",
    "        file = open(newtablename+\"/scatter/\"+'stats.txt', \"w\") \n",
    "        file.write(txt)\n",
    "        file.close()\n",
    "\n",
    "\n",
    "\n",
    "        #######################################################\n",
    "\n",
    "        score_individuals=[]\n",
    "        for sss in range(iterations):\n",
    "            score_individuals.append('score'+str(sss))\n",
    "        df_final_temp=df_final[df_final['datediff_algo_int2']<=3650]\n",
    "        df_final_temp=df_final_temp[df_final_temp['datediff_algo_int2']>=0]\n",
    "        df_final_temp.reset_index(inplace=True,drop=True)\n",
    "        Framingham_temp_algo=df_final_temp['Framingham']\n",
    "        df_final_temp_algo_scores=df_final_temp[score_individuals]\n",
    "\n",
    "        df_final_temp=df_final[df_final['datediff_firstoccur_int2']<=3650]\n",
    "        df_final_temp=df_final_temp[df_final_temp['datediff_firstoccur_int2']>=0]\n",
    "        df_final_temp.reset_index(inplace=True,drop=True)\n",
    "        Framingham_temp_firstoccur=df_final_temp['Framingham']\n",
    "        df_final_temp_firstoccur_scores=df_final_temp[score_individuals]\n",
    "\n",
    "        mean=df_final_temp_firstoccur_scores.mean(axis=1)\n",
    "        std=df_final_temp_firstoccur_scores.std(axis=1)\n",
    "        df_final_temp_firstoccur_scores['mean']=mean\n",
    "        df_final_temp_firstoccur_scores['std']=std\n",
    "        df_final_temp_firstoccur_scores['CV']=df_final_temp_firstoccur_scores['std']/df_final_temp_firstoccur_scores['mean']\n",
    "\n",
    "        df_final_temp_firstoccur_scores['upper']=df_final_temp_firstoccur_scores['mean']+df_final_temp_firstoccur_scores['std']\n",
    "        df_final_temp_firstoccur_scores['under']=df_final_temp_firstoccur_scores['mean']-df_final_temp_firstoccur_scores['std']\n",
    "        df_final_temp_firstoccur_scores['Framingham']=Framingham_temp_firstoccur\n",
    "\n",
    "        df_final_temp_firstoccur_scores_low=df_final_temp_firstoccur_scores[df_final_temp_firstoccur_scores['mean']<=10].reset_index(drop=True)\n",
    "        df_final_temp_firstoccur_scores_mod=df_final_temp_firstoccur_scores[df_final_temp_firstoccur_scores['mean']<=20].reset_index(drop=True)\n",
    "        df_final_temp_firstoccur_scores_mod=df_final_temp_firstoccur_scores_mod[df_final_temp_firstoccur_scores_mod['mean']>10].reset_index(drop=True)\n",
    "        df_final_temp_firstoccur_scores_hig=df_final_temp_firstoccur_scores[df_final_temp_firstoccur_scores['mean']>30].reset_index(drop=True)\n",
    "\n",
    "        firstoccur_total_CV=np.mean(df_final_temp_firstoccur_scores['CV'])\n",
    "        firstoccur_total_sd=np.mean(df_final_temp_firstoccur_scores['std'])\n",
    "        firstoccur_low_CV=np.mean(df_final_temp_firstoccur_scores_low['CV'])\n",
    "        firstoccur_mod_CV=np.mean(df_final_temp_firstoccur_scores_mod['CV'])\n",
    "        firstoccur_hig_CV=np.mean(df_final_temp_firstoccur_scores_hig['CV'])\n",
    "        firstoccur_low_sd=np.mean(df_final_temp_firstoccur_scores_low['std'])\n",
    "        firstoccur_mod_sd=np.mean(df_final_temp_firstoccur_scores_mod['std'])\n",
    "        firstoccur_hig_sd=np.mean(df_final_temp_firstoccur_scores_hig['std'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        mean=df_final_temp_algo_scores.mean(axis=1)\n",
    "        std=df_final_temp_algo_scores.std(axis=1)\n",
    "        df_final_temp_algo_scores['mean']=mean\n",
    "        df_final_temp_algo_scores['std']=std\n",
    "        df_final_temp_algo_scores['CV']=df_final_temp_algo_scores['std']/df_final_temp_algo_scores['mean']\n",
    "\n",
    "        df_final_temp_algo_scores['upper']=df_final_temp_algo_scores['mean']+df_final_temp_algo_scores['std']\n",
    "        df_final_temp_algo_scores['under']=df_final_temp_algo_scores['mean']-df_final_temp_algo_scores['std']\n",
    "        df_final_temp_algo_scores['Framingham']=Framingham_temp_algo\n",
    "\n",
    "        df_final_temp_algo_scores_low=df_final_temp_algo_scores[df_final_temp_algo_scores['mean']<=10].reset_index(drop=True)\n",
    "        df_final_temp_algo_scores_mod=df_final_temp_algo_scores[df_final_temp_algo_scores['mean']<=20].reset_index(drop=True)\n",
    "        df_final_temp_algo_scores_mod=df_final_temp_algo_scores_mod[df_final_temp_algo_scores_mod['mean']>10].reset_index(drop=True)\n",
    "        df_final_temp_algo_scores_hig=df_final_temp_algo_scores[df_final_temp_algo_scores['mean']>30].reset_index(drop=True)\n",
    "\n",
    "        algo_total_CV=np.mean(df_final_temp_algo_scores['CV'])\n",
    "        algo_total_sd=np.mean(df_final_temp_algo_scores['std'])\n",
    "        algo_low_CV=np.mean(df_final_temp_algo_scores_low['CV'])\n",
    "        algo_mod_CV=np.mean(df_final_temp_algo_scores_mod['CV'])\n",
    "        algo_hig_CV=np.mean(df_final_temp_algo_scores_hig['CV'])\n",
    "        algo_low_sd=np.mean(df_final_temp_algo_scores_low['std'])\n",
    "        algo_mod_sd=np.mean(df_final_temp_algo_scores_mod['std'])\n",
    "        algo_hig_sd=np.mean(df_final_temp_algo_scores_hig['std'])\n",
    "\n",
    "        firstoccurcvsdlist=[firstoccur_total_CV,firstoccur_total_sd,firstoccur_low_CV,firstoccur_mod_CV,firstoccur_hig_CV,firstoccur_low_sd,firstoccur_mod_sd,firstoccur_hig_sd]\n",
    "        algocvsdlist=[algo_total_CV,algo_total_sd,algo_low_CV,algo_mod_CV,algo_hig_CV,algo_low_sd,algo_mod_sd,algo_hig_sd]\n",
    "\n",
    "\n",
    "        cvsddf=pd.DataFrame({'algo':algocvsdlist,'firstoccur':firstoccurcvsdlist})\n",
    "        cvsddf.index=['total_CV','total_SD','low_CV','mod_CV','high_CV','low_SD','mod_SD','high_SD']\n",
    "        cvsddf.to_csv(newtablename+'/CV_SD.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #######################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        dfdfdf2=df_final[['age','sex','total_chol','HDL','LDL','TG','Glucose','SBP','DBP','height','weight','Smoking','med_final','DM_final','Framingham','ACC/AHA','framingham_cat','ACC_AHA_cat','category_final','score_final']]\n",
    "        dfdfdf2.columns=['Age','Sex','Total_chol','HDL','LDL','TG','Glucose','SBP','DBP','Height','Weight','Smoking','BP medication','DM','Framingham','ACC/AHA','Framingham category','ACC/AHA category','ChatGPT category','ChatGPT score']\n",
    "\n",
    "        catcolumns=['Smoking','Sex','DM','BP medication','ChatGPT category','Framingham category','ACC/AHA category']\n",
    "\n",
    "        def table1(catcolumn):\n",
    "            nonnormallist=[]\n",
    "            def _normality(self, x):\n",
    "                #print(x.name)\n",
    "\n",
    "                if len(x.values[~np.isnan(x.values)]) >= 20:\n",
    "                    p = stats.shapiro(x.values).pvalue\n",
    "                else:\n",
    "                    p = None\n",
    "                # dropna=False argument in pivot_table does not function as expected\n",
    "                # return -1 instead of None\n",
    "                if pd.isnull(p):\n",
    "                    return -1\n",
    "                if p<=0.05:\n",
    "                    nonnormallist.append(x.name)\n",
    "                return p\n",
    "\n",
    "            TableOne._normality=_normality\n",
    "\n",
    "            def my_custom_test(group1, group2):\n",
    "                \"\"\"\n",
    "                Hypothesis test for test_self_defined_statistical_tests\n",
    "                \"\"\"\n",
    "                my_custom_test.__name__ = \"mannwhitneyu\"\n",
    "                _, pval= scipy.stats.mannwhitneyu(group1, group2)\n",
    "                return pval\n",
    "\n",
    "            nonnormallist=[]\n",
    "            def _normality(self, x):\n",
    "                #print(x.name)\n",
    "\n",
    "                if len(x.values[~np.isnan(x.values)]) >= 20:\n",
    "                    p = stats.shapiro(x.values).pvalue\n",
    "                else:\n",
    "                    p = None\n",
    "                # dropna=False argument in pivot_table does not function as expected\n",
    "                # return -1 instead of None\n",
    "                if pd.isnull(p):\n",
    "                    return -1\n",
    "                if p<=0.05:\n",
    "                    nonnormallist.append(x.name)\n",
    "                return p\n",
    "\n",
    "            TableOne._normality=_normality\n",
    "\n",
    "            table1=TableOne(dfdfdf2,categorical=catcolumns,groupby=[catcolumn],normal_test=True,pval=True,htest_name=True)\n",
    "            nonnormallist=list(set(nonnormallist))\n",
    "            nonnormallist\n",
    "\n",
    "            table1=TableOne(dfdfdf2,categorical=catcolumns,groupby=[catcolumn],normal_test=True,pval=True,htest_name=True,nonnormal=nonnormallist)\n",
    "            try:\n",
    "                os.mkdir(newtablename)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                os.mkdir(newtablename+'/table1')\n",
    "            except:\n",
    "                pass\n",
    "            catcolumn=catcolumn.replace(' ','_')\n",
    "            catcolumn=catcolumn.replace('/','_')\n",
    "            table1.to_html(newtablename+'/table1/'+catcolumn+'.html')\n",
    "\n",
    "        for catcolumn in ['ChatGPT category','Framingham category','ACC/AHA category']:\n",
    "            table1(catcolumn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ff553e",
   "metadata": {},
   "source": [
    "# individual AUROCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3162ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_temp=df_final[df_final['datediff_algo_int2']<=3650]\n",
    "df_final_temp=df_final_temp[df_final_temp['datediff_algo_int2']>=0]\n",
    "df_final_temp.reset_index(inplace=True,drop=True)\n",
    "print(len(df_final_temp))\n",
    "df_final_temp_algo=df_final_temp[['score0','score1','score2','score3','score4','algo_event']]\n",
    "print(np.sum(df_final_temp_algo['algo_event']))\n",
    "\n",
    "df_final_temp=df_final[df_final['datediff_firstoccur_int2']<=3650]\n",
    "df_final_temp=df_final_temp[df_final_temp['datediff_firstoccur_int2']>=0]\n",
    "df_final_temp.reset_index(inplace=True,drop=True)\n",
    "Framingham_temp_firstoccur=df_final_temp['Framingham']\n",
    "print(len(df_final_temp))\n",
    "df_final_temp_firstoccur=df_final_temp[['score0','score1','score2','score3','score4','firstoccur_event']]\n",
    "print(np.sum(df_final_temp_firstoccur['firstoccur_event']))\n",
    "\n",
    "for dfdfdf in ['df_final_temp_algo','df_final_temp_firstoccur']:\n",
    "    dfdfdf2=globals()[dfdfdf]\n",
    "    for scoreint in ['score0','score1','score2','score3','score4']:\n",
    "        fpr,tpr,thres=roc_curve(dfdfdf2[dfdfdf.split('_')[-1]+'_event'],dfdfdf2[scoreint])\n",
    "        roc_auc_temp = round(auc(fpr, tpr),3)\n",
    "        print(dfdfdf.split('_')[-1],scoreint,roc_auc_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b7db43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701f68bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtx4090",
   "language": "python",
   "name": "rtx4090"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
